<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Just for noting</title><link href="https://blog.m157q.tw/" rel="alternate"></link><link href="https://blog.m157q.tw/feeds/tag.rnn.atom.xml" rel="self"></link><id>https://blog.m157q.tw/</id><updated>2017-08-12T17:02:14+08:00</updated><entry><title>台灣資料科學年會之系列活動：深入淺出深度學習 (Dive into Deep Learning)</title><link href="https://blog.m157q.tw/posts/2017/08/12/dive-into-deep-learning-datasci-tw/" rel="alternate"></link><published>2017-08-12T17:02:14+08:00</published><updated>2017-08-12T17:02:14+08:00</updated><author><name>m157q</name></author><id>tag:blog.m157q.tw,2017-08-12:posts/2017/08/12/dive-into-deep-learning-datasci-tw/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;Links  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://foundation.datasci.tw/dive-deep-learning-170812/"&gt;http://foundation.datasci.tw/dive-deep-learning-170812/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://dsc.kktix.cc/events/series-events-081213"&gt;https://dsc.kktix.cc/events/series-events-081213&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slides  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://drive.google.com/file/d/0B9cCeTKOkfWIVF9CeXpXaC1lUVk/view?usp=sharing"&gt;DiveDL_0326_v1.pdf&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Regression&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;適用場景  &lt;ul&gt;
&lt;li&gt;股票預測  &lt;/li&gt;
&lt;li&gt;無人車方向調整  &lt;/li&gt;
&lt;li&gt;推薦系統  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;步驟  &lt;ul&gt;
&lt;li&gt;決定 Model  &lt;/li&gt;
&lt;li&gt;評估所使用的函數夠不夠好  &lt;ul&gt;
&lt;li&gt;Loss Funciton  &lt;ul&gt;
&lt;li&gt;output 分數低，代表 loss 少，所以比較好。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;找出表現最好的 Loss Function  &lt;ul&gt;
&lt;li&gt;利用 Gradient Descent 來找  &lt;ul&gt;
&lt;li&gt;縱軸為 L 的 output，橫軸為 w  &lt;/li&gt;
&lt;li&gt;L 對 w 偏微分，取得其切線斜率  &lt;/li&gt;
&lt;li&gt;切線斜率為負時，增加 w，來取得較低的 L output  &lt;/li&gt;
&lt;li&gt;切線斜率為正時，減少 w，來取得較低的 L output  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;非 Linear 的話，會出現 Local optimal 和 Global optimal 的狀況  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;得到 Model  &lt;/li&gt;
&lt;li&gt;Model Generalization  &lt;ul&gt;
&lt;li&gt;嘗試不同的 Model  &lt;/li&gt;
&lt;li&gt;太過複雜的 Model 會出現 Overfitting 的狀況  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Classification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;分類  &lt;ul&gt;
&lt;li&gt;Binary Classification  &lt;ul&gt;
&lt;li&gt;Yes/No  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;Spam Filtering  &lt;ul&gt;
&lt;li&gt;把 email 裡面的詞都當作一個 feature，透過 trained model 來得到 Boolean 的結果。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-Class Classification  &lt;ul&gt;
&lt;li&gt;判斷是哪個種類  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;餵入圖片，判斷是哪種動物  &lt;/li&gt;
&lt;li&gt;判斷新聞是屬於哪一種主題  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Introduction to ML &amp;amp; DL&lt;/h1&gt;
&lt;h2&gt;Basic Deep Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stacked function learned by machine  &lt;/li&gt;
&lt;li&gt;Deep Learning 三步驟  &lt;ul&gt;
&lt;li&gt;Define a set of function  &lt;/li&gt;
&lt;li&gt;Godness of function  &lt;/li&gt;
&lt;li&gt;pick the best function  &lt;/li&gt;
&lt;li&gt;(和 ML 很像）  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 1: Define a set of function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Neural Network  &lt;ul&gt;
&lt;li&gt;Neuron: input, weights, bias, Activation function  &lt;/li&gt;
&lt;li&gt;將多個 Neuron 組合在一起，形成 Neuron Network  &lt;/li&gt;
&lt;li&gt;愈多層的話需要調整的參數越多  &lt;/li&gt;
&lt;li&gt;不同的 Connections 可以形成不同的 Neural Network  &lt;ul&gt;
&lt;li&gt;Fully-Connected Feedforward Network  &lt;ul&gt;
&lt;li&gt;每一個 Neuron 都跟前一個相連，會一直把數值傳下去。  &lt;/li&gt;
&lt;li&gt;Input Layer + Hidden Layers + Output Layer  &lt;/li&gt;
&lt;li&gt;"Deep" means multiple hidden layers  &lt;ul&gt;
&lt;li&gt;DNN 的 hidden layers 至少要大於 2  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why Deep?  &lt;ul&gt;
&lt;li&gt;Fat + Shallow vs Thin + Deep  &lt;ul&gt;
&lt;li&gt;在數學上被證明是可以用一層很寬的 layer 來取代多層的 layers，但為什麼不用？  &lt;/li&gt;
&lt;li&gt;因為只用一層的話會需要使用到更多的 Neurons。（可以用類似 Logic Gates 簡化的方式來想）  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Examples  &lt;ul&gt;
&lt;li&gt;AlexNet (2012): 8 layers, 16.4%  &lt;/li&gt;
&lt;li&gt;VGG (2014): 19 layers, 7.3%  &lt;/li&gt;
&lt;li&gt;GoogleNet (2014): 22 layers, 6.7%  &lt;/li&gt;
&lt;li&gt;Residual Net (2015): 152 layers, 3.57%  &lt;ul&gt;
&lt;li&gt;人類自己把所有的 training data 看完後下去做測試，error rate 大概是 4~5%  &lt;/li&gt;
&lt;li&gt;首度超越人類  &lt;/li&gt;
&lt;li&gt;因為疊了很多層，所以可能有些資訊會在傳遞中遺失，所以使用了 Special structure，會把一些一開始就學到的很重要 information 直接保留下來，確保不會在傳遞過程中遺失。  &lt;/li&gt;
&lt;li&gt;使用 Softmax layer 來當 Output layer  &lt;ul&gt;
&lt;li&gt;可以對 output 的數值做 normalize，直接以機率的方式呈現結果。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;Handwriting Digit Recognition  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Input =&amp;gt; Neuron Network =&amp;gt; Output  &lt;/li&gt;
&lt;li&gt;Neuron Network =&amp;gt; A function set containing the candidates  &lt;/li&gt;
&lt;li&gt;FAQ  &lt;ul&gt;
&lt;li&gt;要用幾層？每層要用多少 Neuron？  &lt;ul&gt;
&lt;li&gt;試誤 + 直覺  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;我們可以自己設計 neuron network structure 嗎？  &lt;ul&gt;
&lt;li&gt;有很多不同的結構可以選擇  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有辦法讓程式自動幫我們決定要使用哪種 structure  &lt;ul&gt;
&lt;li&gt;有，但還沒有被研究的非常透徹。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 2: goodness of function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Loss  &lt;ul&gt;
&lt;li&gt;A good function should make the loss of all examples as small as possible.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Total Loss  &lt;ul&gt;
&lt;li&gt;As small as possible  &lt;/li&gt;
&lt;li&gt;Find a function in function set that minimizes total loss  &lt;/li&gt;
&lt;li&gt;Find the network parameter &lt;code&gt;θ*&lt;/code&gt; that minimize total loss  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 3: pick the best function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Gradient Descent  &lt;ul&gt;
&lt;li&gt;Local minima  &lt;ul&gt;
&lt;li&gt;Very slow at the plateau  &lt;/li&gt;
&lt;li&gt;Stuck at saddle point  &lt;/li&gt;
&lt;li&gt;Stuck at local minima  &lt;/li&gt;
&lt;li&gt;Gradient descent never guarantee global minima  &lt;ul&gt;
&lt;li&gt;Use different &amp;amp; random initial point to reach different minima  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Even AlphaGo using this approach  &lt;ul&gt;
&lt;li&gt;其實 AI 並沒有那麼厲害，他們也是像探索戰爭迷霧那樣，一步一步去探索和嘗試的。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Deep Learning Toolkit&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Backpropagation  &lt;ul&gt;
&lt;li&gt;An efficient way to compute &lt;code&gt;∂L/∂w&lt;/code&gt; in neural network  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Frameworks  &lt;ul&gt;
&lt;li&gt;TensorFlow  &lt;ul&gt;
&lt;li&gt;比較多人在用且資料比較多  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Torch  &lt;/li&gt;
&lt;li&gt;Pytorch  &lt;ul&gt;
&lt;li&gt;比較多人在用且資料比較多  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Theano  &lt;ul&gt;
&lt;li&gt;AlexNet 的作者  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microsoft CNTK  &lt;/li&gt;
&lt;li&gt;Caffe  &lt;/li&gt;
&lt;li&gt;DSSTNE  &lt;/li&gt;
&lt;li&gt;mxnet  &lt;/li&gt;
&lt;li&gt;Chainer  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有 input 和 output，就可以使用這些工具幫你找尋合適的 Function Set  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Keras&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow 和 Theano 的 Wrapper  &lt;/li&gt;
&lt;li&gt;非常容易寫  &lt;/li&gt;
&lt;li&gt;雖然可以細部調整的地方沒有直接使用 TensorFlow 和 Theano 來的多，但有足夠的彈性做一些調整。  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Learning Recipe&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 Training Data 上的表現好嗎？  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不好  &lt;ul&gt;
&lt;li&gt;重新 train  &lt;/li&gt;
&lt;li&gt;可能原因  &lt;ul&gt;
&lt;li&gt;no good function exists: bad hypothesis function set =&amp;gt; reconstruct the model architecture  &lt;/li&gt;
&lt;li&gt;cannot find a good function: local optima =&amp;gt; change the training strategy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Testing Data 上的表現好嗎？  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不好的話就是 Overfitting，要重新 train model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Overfitting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;High variance  &lt;/li&gt;
&lt;li&gt;可能的解法  &lt;ul&gt;
&lt;li&gt;more training samples  &lt;/li&gt;
&lt;li&gt;dropout  &lt;ul&gt;
&lt;li&gt;每次 random 讓數個 node 不工作  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;降維  &lt;ul&gt;
&lt;li&gt;PCA  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Concluding Remarks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;3 steps of Basic Machine Learning 很重要  &lt;/li&gt;
&lt;li&gt;Stacked functions  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Part II: Variants of Neural Nets&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Convolutional Neural Network (CNN)  &lt;/li&gt;
&lt;li&gt;Recurrent Neural Network (RNN)  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Convolutional Neural Network (CNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在影像處理上被廣泛使用  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why CNN for Image?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image.  &lt;ul&gt;
&lt;li&gt;A neuron does not have to see the whole image to discover pattern.  &lt;/li&gt;
&lt;li&gt;Connecting to small region with less parameters.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions.  &lt;/li&gt;
&lt;li&gt;Subsampling the pixels will not change the object.  &lt;ul&gt;
&lt;li&gt;算是處理 image 上獨有的特性  &lt;/li&gt;
&lt;li&gt;We can subsmaple the pixel to make image smaller  &lt;ul&gt;
&lt;li&gt;Less parameters for the network to process the image  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;The Whole CNN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Image =&amp;gt; &lt;code&gt;{Convolution =&amp;gt; Max Pooling}*N&lt;/code&gt; =&amp;gt; Flatten =&amp;gt; Fully Connected Feedforward Network  &lt;/li&gt;
&lt;li&gt;特性  &lt;ul&gt;
&lt;li&gt;和 Convolution 有關  &lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image.  &lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;和 Max Pooling 有關  &lt;ul&gt;
&lt;li&gt;Subsampling the pixels will not change the object  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Image Recognition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Local Connectivity  &lt;ul&gt;
&lt;li&gt;Neurons connected to a small region  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameter Sharing  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The same feature in different positions  &lt;ul&gt;
&lt;li&gt;Neurons share the same weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Different features in the same position  &lt;ul&gt;
&lt;li&gt;Neurons have different weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convolutional Layers  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Hyper-parameters of CNN  &lt;ul&gt;
&lt;li&gt;Stride  &lt;ul&gt;
&lt;li&gt;要隔多少去算下一個 information  &lt;/li&gt;
&lt;li&gt;如果覺得這張圖上的 information 是非常鬆散的，那 stride 就可以設高一點，讓他多隔幾層再去找 pattern  &lt;/li&gt;
&lt;li&gt;如果覺得這張圖上的 information 是非常緊密的，那 stride 就只能設低一點。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Padding  &lt;ul&gt;
&lt;li&gt;讓每一層的數值不要減少的太快  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pooling Layer  &lt;ul&gt;
&lt;li&gt;Max Pooling  &lt;ul&gt;
&lt;li&gt;把最大的值保存下來  &lt;/li&gt;
&lt;li&gt;Image processing 比較常使用 Max Pooling  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Average Pooling  &lt;ul&gt;
&lt;li&gt;把平均的數值保存下來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;壓縮資訊，減少下一層需要參數的量，使其更有效率。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why Deep Learing works for image recogniton?  &lt;ul&gt;
&lt;li&gt;每個 node 會學習一些簡單的筆劃，組合起來後才會變成一個字。  &lt;/li&gt;
&lt;li&gt;愈前面的結果會愈簡單和基本，可能只是些筆劃，經過 Convolution 和 Max Pooling 後，可以用被壓縮後的較少資訊學習比較抽象的組合。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fully-Connected Layer  &lt;ul&gt;
&lt;li&gt;Global feature extraction  &lt;/li&gt;
&lt;li&gt;Softmax Layer: Classifier  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What CNN Learned  &lt;ul&gt;
&lt;li&gt;[AlexNet]  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DNN are easily fooled  &lt;ul&gt;
&lt;li&gt;可以捏造一些奇怪的 input，看起來只是一些 noise，因為 DNN 會特別著重某些 pattern，所以會將這些圖誤判為目標物。  &lt;/li&gt;
&lt;li&gt;滿多資安的論文現在在探討攻擊 DNN 的手法。  &lt;/li&gt;
&lt;li&gt;Visualizing CNN  &lt;ul&gt;
&lt;li&gt;調整 noise 的 input，使其 filter response 更接近目標物的 filter response，有點像是反過來的 training  &lt;/li&gt;
&lt;li&gt;透過 Gradient Ascent 去微調  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://deepdreamgenerator.com/"&gt;https://deepdreamgenerator.com/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Deep Style  &lt;ul&gt;
&lt;li&gt;一張圖保留 Content  &lt;/li&gt;
&lt;li&gt;另一張圖保留 Style  &lt;/li&gt;
&lt;li&gt;然後去調整保留 Content 的那張圖，並使用另一張圖的 Style  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Go Playing （下圍棋）  &lt;ul&gt;
&lt;li&gt;Conditions  &lt;ul&gt;
&lt;li&gt;Input: 目前棋盤的狀況  &lt;/li&gt;
&lt;li&gt;Output: 下一步應該下哪裡？  &lt;/li&gt;
&lt;li&gt;19x19 vector  &lt;/li&gt;
&lt;li&gt;black = 1, white = -1, none = 0  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fully-Connected Feedforward Network could be used, but why CNN?  &lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image  &lt;ul&gt;
&lt;li&gt;棋譜會有一些固定的 pattern  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions  &lt;ul&gt;
&lt;li&gt;同樣的 pattern 有可能出現在棋盤上不同的地方  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Subsampling the pixels will not change the object  &lt;ul&gt;
&lt;li&gt;把棋譜作 subsampling 會讓整個棋譜的結果失真  &lt;/li&gt;
&lt;li&gt;因為 Subsampling 只和 Max Pooling Layer 有關，所以在 AlphaGo 的論文中有提到只有使用 Convolutional Layer，把 Max Pooling Layer 拿掉了。  &lt;/li&gt;
&lt;li&gt;如果不是很熟悉下圍棋以及 DNN 的 domain knowledge 的話，直接拿 CNN 去做是訓練不出什麼結果的，這也是為什麼 Alpha Go 會需要像黃士傑博士這樣會下圍棋又懂 Machine Learning 的人。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Recurrent Neural Network (RNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Example Application  &lt;ul&gt;
&lt;li&gt;Slot Filling  &lt;ul&gt;
&lt;li&gt;Solved by Feedforward Network?  &lt;ul&gt;
&lt;li&gt;Input: a word  &lt;/li&gt;
&lt;li&gt;Output: probability distribution that the input word belonging to the slots  &lt;/li&gt;
&lt;li&gt;Problem  &lt;ul&gt;
&lt;li&gt;Arrive Taipei on November 2nd  &lt;ul&gt;
&lt;li&gt;Taipei 是目的地  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Leave Taipei on November 2nd  &lt;ul&gt;
&lt;li&gt;Taipei 是出發地  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用 RNN 來解決  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One-Hot Vector  &lt;ul&gt;
&lt;li&gt;1-of-N Encoding  &lt;/li&gt;
&lt;li&gt;有 N 個詞就用 N 維的矩陣來表示，如果該字有出現的話值就是 1，其他值就會是 0。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RNN  &lt;ul&gt;
&lt;li&gt;The output of hidden layer are stored in the memory  &lt;/li&gt;
&lt;li&gt;Memory can be considered as another input  &lt;/li&gt;
&lt;li&gt;每一層都是拿現在看到的資訊和上一層的 memory 當成 input  &lt;/li&gt;
&lt;li&gt;不會因為層數比較多（語句比較長）就導致參數變多，參數的數量都是一樣的。  &lt;/li&gt;
&lt;li&gt;存在 memory 的 value 會影響最終的 prediction  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep RNN: 多層  &lt;/li&gt;
&lt;li&gt;Why use RNN in language processing?  &lt;ul&gt;
&lt;li&gt;因為語言是有時間順序的  &lt;/li&gt;
&lt;li&gt;如果 input 是時間順序非常重要的話，就可以考慮用 RNN 來做。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bidirectional RNN  &lt;ul&gt;
&lt;li&gt;將 input 反向來作並加入 memory  &lt;/li&gt;
&lt;li&gt;缺點是會比較費時  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning Target  &lt;ul&gt;
&lt;li&gt;會比較複雜一些  &lt;/li&gt;
&lt;li&gt;一句話有五個詞，訓練一句話等於要拿到 5 個 targets  &lt;ul&gt;
&lt;li&gt;因為要判斷每個詞的 label  &lt;/li&gt;
&lt;li&gt;因為彼此是有順序相依性的，所以 loss 會是每層 layer 相加  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training Difficulty - Rough Error Surface  &lt;ul&gt;
&lt;li&gt;The error surface is either very flat or very steep  &lt;ul&gt;
&lt;li&gt;非常難學習  &lt;/li&gt;
&lt;li&gt;所以會有一些各式各樣的小技巧出現在 RNN 裏面  &lt;ul&gt;
&lt;li&gt;Clipping  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Large &lt;code&gt;δL/δw&lt;/code&gt; =&amp;gt; Large Learning rate  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-One  &lt;ul&gt;
&lt;li&gt;Input is a vector sequence, but output is only one vector  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-Many (Output is shorter)  &lt;ul&gt;
&lt;li&gt;Both input and output are sequences, but the output is shorter  &lt;/li&gt;
&lt;li&gt;E.g. Speech Recognition  &lt;ul&gt;
&lt;li&gt;Input: vector sequence  &lt;/li&gt;
&lt;li&gt;Output: character sequence  &lt;/li&gt;
&lt;li&gt;Connectionist Temporal Classification (CTC)  &lt;ul&gt;
&lt;li&gt;加了一個額外的 symble &lt;code&gt;ϕ&lt;/code&gt; 來代表 Null  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;好好好棒棒棒棒&lt;/code&gt; vs &lt;code&gt;好ϕϕ棒ϕϕ棒&lt;/code&gt;  &lt;ul&gt;
&lt;li&gt;這樣就可以知道到底是一個棒還是兩個棒  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-Many (Output is no limitation)  &lt;ul&gt;
&lt;li&gt;Both input and output are sequences with different lengths  &lt;ul&gt;
&lt;li&gt;Sequence to sequence learning  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;E.g. Machine Translation  &lt;ul&gt;
&lt;li&gt;"Machine Learning" =&amp;gt; "機器學習"  &lt;/li&gt;
&lt;li&gt;Problem: Don't know when to stop  &lt;ul&gt;
&lt;li&gt;加上一個代表斷句或結尾的符號  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Image Caption Generation  &lt;ul&gt;
&lt;li&gt;給一張圖，描述出圖裏面有什麼  &lt;/li&gt;
&lt;li&gt;將圖餵給 CNN 後，會產出一個代表整章圖的 vector  &lt;/li&gt;
&lt;li&gt;將 vector 餵給 RNN  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.captionbot.ai/"&gt;http://www.captionbot.ai/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Video Caption Generation  &lt;ul&gt;
&lt;li&gt;每一個 Video 用 CNN  &lt;/li&gt;
&lt;li&gt;Video 裡面的每一張 Image 用 RNN  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Chit-Chat Bot  &lt;ul&gt;
&lt;li&gt;拿對話中其中一方的話當 input，另一方的話當 output 去訓練。  &lt;/li&gt;
&lt;li&gt;比較常用到 &lt;a href="https://en.wikipedia.org/wiki/Long_short-term_memory"&gt;LSTM&lt;/a&gt;  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sci-Fi Short Film generated by AI - SUNSPRING  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=LY7x2lhqj"&gt;https://www.youtube.com/watch?v=LY7x2lhqj&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attention and Memory  &lt;ul&gt;
&lt;li&gt;Question =&amp;gt; Organize =&amp;gt; Answer  &lt;ul&gt;
&lt;li&gt;被稱做 Attention  &lt;/li&gt;
&lt;li&gt;只會拿有用的資訊出來回答  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attention on Sensory Info  &lt;ul&gt;
&lt;li&gt;Info from the sensors =&amp;gt; Sensory Memory == Attention ==&amp;gt; Working Memeory == Encode ==&amp;gt; Long-term Memory  &lt;/li&gt;
&lt;li&gt;Logn-term Memory == Retrieval ==&amp;gt; Working Memory  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Machine Translation with Attention  &lt;ul&gt;
&lt;li&gt;Keyword: "Attentional sequence to sequence model"  &lt;/li&gt;
&lt;li&gt;先用 match 判斷跟哪一塊的相似程度最高  &lt;/li&gt;
&lt;li&gt;目前 Google Translation 就是用這個 model 實現的  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Speech Recognition with Attention  &lt;ul&gt;
&lt;li&gt;比較深色的地方就是 Attention 比較高的部份  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Image Captioning with Attention  &lt;ul&gt;
&lt;li&gt;從錯誤的 prediction 中去瞭解判斷錯誤的可能原因  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Video Captioning with Attention  &lt;/li&gt;
&lt;li&gt;Reading Comprehension  &lt;ul&gt;
&lt;li&gt;Document =&amp;gt; 被切分成不同的詞被當作 feature  &lt;/li&gt;
&lt;li&gt;Question == RNN ==&amp;gt; q vector  &lt;/li&gt;
&lt;li&gt;根據 q vector 去決定哪一個句子最相關，再放入 DNN 裡頭去回答  &lt;/li&gt;
&lt;li&gt;Hopping  &lt;ul&gt;
&lt;li&gt;Memory Network  &lt;ul&gt;
&lt;li&gt;有可能第一次得到的結果不夠準確  &lt;/li&gt;
&lt;li&gt;用抽取出來資訊再做一次 Attention，再得到新的 information 並把它抽取出來。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When the input is a very long sequence or an image  &lt;ul&gt;
&lt;li&gt;Pay attention on partial of the input object each time  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In RNN/LSTM, larger memory implies more parameters  &lt;ul&gt;
&lt;li&gt;Increasing memory size will not increasing parameters  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Neural Turing Machine  &lt;ul&gt;
&lt;li&gt;an advanced RNN/LSTM  &lt;/li&gt;
&lt;li&gt;把 Long-term Memory 裡頭的資訊 retrieve 出來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Part III: Beyond Supervised Learning &amp;amp; Recent Trends (Unsupervised Learning)&lt;/h1&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Big data != Big annotated data  &lt;ul&gt;
&lt;li&gt;What can we do if there is no sufficient labelled training data?  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Machine learning techniques include:  &lt;ul&gt;
&lt;li&gt;Supervised learning (if we have labelled data)  &lt;/li&gt;
&lt;li&gt;Reinforcement learning (if we have an environment for reward)  &lt;/li&gt;
&lt;li&gt;Unsupervised learning (if we do not have labelled data)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Semi-Supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;應用環境  &lt;ul&gt;
&lt;li&gt;沒有全部的 input data 都有 label 時  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;The distribution of the unlabeled data provides some cues  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Transfer Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;應用環境  &lt;ul&gt;
&lt;li&gt;Input data 中沒有 output 想要的 class label  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Using sufficient labeled data to learn a CNN  &lt;/li&gt;
&lt;li&gt;Using this CNN as feature extractor  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;舉例  &lt;ul&gt;
&lt;li&gt;研究生 vs 漫畫家  &lt;ul&gt;
&lt;li&gt;研究生 == 漫畫家  &lt;/li&gt;
&lt;li&gt;指導教授 == 責任編輯  &lt;/li&gt;
&lt;li&gt;跑實驗 == 畫分鏡  &lt;/li&gt;
&lt;li&gt;投稿期刊 == 投稿 Jump  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Unsupervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Representation Learning: 化繁為簡  &lt;/li&gt;
&lt;li&gt;Generative Model: 無中生有  &lt;/li&gt;
&lt;li&gt;化繁為簡和無中生有的過程是相反的  &lt;ul&gt;
&lt;li&gt;化繁為簡：拿到很多跟樹有關的圖片，簡化得出一個代表樹的 output，學習到的是這些圖片共同的特徵  &lt;/li&gt;
&lt;li&gt;無中生有：code 經過 function 之後就生成很多跟樹很像的圖片  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Latent Factors  &lt;ul&gt;
&lt;li&gt;共同特徵  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;化繁為簡 Representation Learning  &lt;ul&gt;
&lt;li&gt;Autoencoder  &lt;ul&gt;
&lt;li&gt;希望能把比較重要的資訊壓縮到比較小的 pattern 裏面  &lt;/li&gt;
&lt;li&gt;represent the images of digits in a more compact way  &lt;/li&gt;
&lt;li&gt;Output of the hidden layer is the code  &lt;/li&gt;
&lt;li&gt;Deep autoencoder  &lt;/li&gt;
&lt;li&gt;Similar Image Retrieval  &lt;/li&gt;
&lt;li&gt;可以把 image 最重要的 feature 保留起來  &lt;/li&gt;
&lt;li&gt;For DNN Pre-Training  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word Vector/Embedding  &lt;ul&gt;
&lt;li&gt;Machine learn the meaning of words from reading a lot of documents without supervision  &lt;/li&gt;
&lt;li&gt;A word can be understood by its context  &lt;/li&gt;
&lt;li&gt;類似的句型中，同樣位置的不相同詞可能有高度相關性  &lt;/li&gt;
&lt;li&gt;Prediction-Based  &lt;ul&gt;
&lt;li&gt;給前面的字 predict 下一個字 (Linear Model)  &lt;ul&gt;
&lt;li&gt;前面的字當 input，後面的字當 output，一直這樣接下去。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Various Architecture  &lt;ul&gt;
&lt;li&gt;Continuous bag of word (CBOW) model  &lt;ul&gt;
&lt;li&gt;給兩邊的字 predict 中間的字  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Skip-gram  &lt;ul&gt;
&lt;li&gt;給中間的字 predict 兩邊的字  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;完全不需要 label data，程式可以自己去學習這些詞之間的關係  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;無中生有 Generative model  &lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;想讓程式自動幫我們生不同的 training data  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.openai.com/generative-models/"&gt;https://blog.openai.com/generative-models/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PixelRNN  &lt;ul&gt;
&lt;li&gt;To create an image, generating a pixel each time  &lt;/li&gt;
&lt;li&gt;Can be trained just with a large collection of images without any annotation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generative Adversarial Network (GAN)  &lt;ul&gt;
&lt;li&gt;Discriminative vs Generative Models  &lt;ul&gt;
&lt;li&gt;Discriminative  &lt;ul&gt;
&lt;li&gt;learns a function that maps the input data (x) to some desired output class label (y)  &lt;ul&gt;
&lt;li&gt;directly learn the conditional distribution P(y|x)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generative  &lt;ul&gt;
&lt;li&gt;tries to learn the joint probability of the input data and labels simultaneously, i.e. P(x,y)  &lt;ul&gt;
&lt;li&gt;can be converted to P(y|x) for classification via Bayes rule  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;generative models have the potential to understand and explain&lt;br /&gt;
the underlying structure of the input data even when there are no labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;跟演化的感覺有點類似  &lt;ul&gt;
&lt;li&gt;Generator  &lt;ul&gt;
&lt;li&gt;Hidden Layer (code) ===decode===&amp;gt; output layer =&amp;gt; output  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Two competing neural networks: generator &amp;amp; discriminator  &lt;/li&gt;
&lt;li&gt;noise ==generator==&amp;gt; generator sample =&amp;gt; discriminator ==yes/no==&amp;gt; data sample  &lt;/li&gt;
&lt;li&gt;generator 生出圖片，discriminator 判斷這張產生出來的圖片是不是真的  &lt;/li&gt;
&lt;li&gt;彼此之間會互相競爭學習  &lt;/li&gt;
&lt;li&gt;Training two networks jointly =&amp;gt; the generator knows how to adapt its parameters in order to produce output data that can fool the discriminator  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Examples  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://openai.com/blog/generative-models"&gt;Cifar-10&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Generated Bedrooms  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mattya/chainer-DCGAN"&gt;Comics Drawing&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Pokémon Creation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Agent, Environment 之間彼此是可以互動的  &lt;/li&gt;
&lt;li&gt;Environment 會給 Agent 一個 Observation  &lt;/li&gt;
&lt;li&gt;Agent 會對這個 Observation 做出 Action  &lt;/li&gt;
&lt;li&gt;Environment 會根據 Action 的不同給予 Agent 不同的 Reward  &lt;/li&gt;
&lt;li&gt;根據 Reward 來學習要做或不做哪些行為  &lt;/li&gt;
&lt;li&gt;Agent learns to take actions to maximize expected reward.  &lt;/li&gt;
&lt;li&gt;困難點  &lt;ul&gt;
&lt;li&gt;可能的 sequence 是非常龐大的  &lt;/li&gt;
&lt;li&gt;很難調整，因為只拿得到一連串的 Actions 之後的 Reward，無法確定到底是錯在哪一個 Action  &lt;/li&gt;
&lt;li&gt;Reward may be delayed  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supervised vs Reinforcement  &lt;ul&gt;
&lt;li&gt;Supervised  &lt;ul&gt;
&lt;li&gt;就像在學校裏面，每一步都有老師會帶領你，告訴你每一步是對是錯  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement  &lt;ul&gt;
&lt;li&gt;做了一連串的動作以後，到一個正面或負面的回饋，不確定到底問題出錯在哪一個地方。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;範例  &lt;ul&gt;
&lt;li&gt;走迷宮  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning Approach  &lt;ul&gt;
&lt;li&gt;Policy-based RL  &lt;ul&gt;
&lt;li&gt;Search directly for optimal policy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Value-based RL  &lt;ul&gt;
&lt;li&gt;Estimate the optimal value function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model-based RL  &lt;ul&gt;
&lt;li&gt;Build a model of the environment  &lt;/li&gt;
&lt;li&gt;Plan (e.g. by lookahead) using model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning  &lt;ul&gt;
&lt;li&gt;Idea: deep learning for reinforcement learning  &lt;ul&gt;
&lt;li&gt;Use deep neural networks to represent  &lt;/li&gt;
&lt;li&gt;Optimize loss function by SGD  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Value Function Approximation  &lt;/li&gt;
&lt;li&gt;Q-Networks  &lt;ul&gt;
&lt;li&gt;Q-networks represent value functions with weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Q-Learning  &lt;ul&gt;
&lt;li&gt;Goal: estimate optimal Q-values  &lt;ul&gt;
&lt;li&gt;Optimal Q-values obey a Bellman equation  &lt;/li&gt;
&lt;li&gt;Value iteration algorithms solve the Bellman equation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Q-Networks (DQN)  &lt;/li&gt;
&lt;li&gt;Stability Issues with Deep RL  &lt;ul&gt;
&lt;li&gt;Naive Q-learning oscillates or diverges with neural nets  &lt;ul&gt;
&lt;li&gt;Data is sequential  &lt;ul&gt;
&lt;li&gt;Successive samples are correlated, non-iid (independent and&lt;br /&gt;
identically distributed)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Policy changes rapidly with slight changes to Q-values  &lt;ul&gt;
&lt;li&gt;Policy may oscillate  &lt;/li&gt;
&lt;li&gt;Distribution of data can swing from one extreme to another  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scale of rewards and Q-values is unknown  &lt;ul&gt;
&lt;li&gt;Naive Q-learning gradients can be unstable when backpropagated  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stable Solutions for DQN  &lt;ul&gt;
&lt;li&gt;DQN provides a stable solutions to deep value-based RL  &lt;ul&gt;
&lt;li&gt;Use experience replay  &lt;ul&gt;
&lt;li&gt;Break correlations in data, bring us back to iid setting  &lt;/li&gt;
&lt;li&gt;Learn from all past policies  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Freeze target Q-network  &lt;ul&gt;
&lt;li&gt;Avoid oscillation  &lt;/li&gt;
&lt;li&gt;Break correlations between Q-network and target  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clip rewards or normalize network adaptively to sensible range  &lt;ul&gt;
&lt;li&gt;Robust gradients  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DQN in Atari  &lt;ul&gt;
&lt;li&gt;Goal: end-to-end learning of values Q(s, a) from pixels  &lt;ul&gt;
&lt;li&gt;Input: state is stack of raw pixels from last 4 frames  &lt;/li&gt;
&lt;li&gt;Output: Q(s, a) for all joystick/button positions a  &lt;/li&gt;
&lt;li&gt;Reward is the score change for that step  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DQN in E2E Task-Completion Bot  &lt;ul&gt;
&lt;li&gt;Simulated User  &lt;ul&gt;
&lt;li&gt;Generate interactions based on a predefined fake goal  &lt;/li&gt;
&lt;li&gt;Automatically learn strategy by training on the simulated data  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model-Based Deep RL  &lt;ul&gt;
&lt;li&gt;Goal: learn a transition model of the environment and plan based on the transition model  &lt;/li&gt;
&lt;li&gt;Model-based deep RL is challenging, and so far has failed in Atari  &lt;/li&gt;
&lt;li&gt;Model-Based Deep RL in AlphaGo  &lt;ul&gt;
&lt;li&gt;Monte-Carlo tree search (MCTS)  &lt;ul&gt;
&lt;li&gt;MCTS simulates future trajectories  &lt;/li&gt;
&lt;li&gt;Builds large lookahead search tree with millions of positions  &lt;/li&gt;
&lt;li&gt;State-of-the-art Go programs use MCTS  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolutional Networks  &lt;ul&gt;
&lt;li&gt;12-layer CNN trained to predict expert moves  &lt;/li&gt;
&lt;li&gt;Raw CNN (looking at 1 position, no search at all) equals performance of MoGo with 105 position search tree  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;More Applications  &lt;ul&gt;
&lt;li&gt;AlphaGo  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0JL04JJjocc"&gt;Flying Helicoptor&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0xo1Ldx3L5Q"&gt;Driving&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bloomberg.com/news/articles/2016-07-19/google-cuts-its-giant-electricity-bill-with-deepmind-powered-ai"&gt;Google Cuts Its Giant Electricity Bill With DeepMind-Powered AI&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://universe.openai.com/"&gt;OpenAI Universe&lt;/a&gt;  &lt;ul&gt;
&lt;li&gt;Software platform for measuring and training an AI's general&lt;br /&gt;
intelligence via the &lt;a href="https://gym.openai.com/"&gt;OpenAI gym&lt;/a&gt; environment  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning &amp;amp; Deep Learning 需要  &lt;ul&gt;
&lt;li&gt;足夠的運算資源  &lt;/li&gt;
&lt;li&gt;各種經驗及技巧  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;FAQ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep Learning 的 model 會是 non-linear 的  &lt;/li&gt;
&lt;li&gt;機器翻譯目前在台灣的狀況如何？要如何著手？  &lt;ul&gt;
&lt;li&gt;機器翻譯的話，目前在國外算是滿成熟的，目前會使用 RNN 來做。  &lt;/li&gt;
&lt;li&gt;如果是台語的部份，目前好像比較少看到，會是個還有發展空間的方向。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;為什麼需要 Activation Function？他在 Deep Learning 中扮演的角色是什麼？  &lt;ul&gt;
&lt;li&gt;處理 non-linear 的部份，如果沒有 Actication Function 的話，多層的結果用一層就可以去表示。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;為什麼會選擇 Sigmoid 作為 Activation Function?  &lt;ul&gt;
&lt;li&gt;其實有很多種 Activation Function，拿 Sigmoid 來講是因為他比較簡單，把 output 壓在 -1~1 之間  &lt;/li&gt;
&lt;li&gt;另外一個比較常見的是 Relu 這個 Activation Function  &lt;ul&gt;
&lt;li&gt;0 以下的就刪除掉  &lt;/li&gt;
&lt;li&gt;避免 information 被壓縮的太小，用來解決經過太多層之後 information 被壓得太小。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Learning 的最佳化要具備哪些能力  &lt;ul&gt;
&lt;li&gt;如果是純理論的部份會跟數學方面相關。  &lt;/li&gt;
&lt;li&gt;但如果是實務上的 task，會跟該 task 的 domain knowledge 比較相關。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CNN 對於影像旋轉是否也有夠好的識別度？  &lt;ul&gt;
&lt;li&gt;第一個作法就是把你的 training data 也旋轉過再丟進去訓練  &lt;/li&gt;
&lt;li&gt;另外一個作法是使用會考慮旋轉相關的 model 放進去 train，input data 不需要特別旋轉過  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;學 Machine Learning 需要學習微積分、統計和線性代數嗎？  &lt;ul&gt;
&lt;li&gt;基本的微積分概念是要的，但沒有很複雜，如果完全不會微分的話要學一下。  &lt;/li&gt;
&lt;li&gt;統計的話基本概念要有，但不會太多。&lt;br /&gt;
 線性代數是最重要的，會看到很多 vector, matrix 以及 space 上的處理，有很多假設是必須要知道的。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Deep Learning"></category><category term="DNN"></category><category term="CNN"></category><category term="RNN"></category><category term="Machine Learning"></category></entry></feed>