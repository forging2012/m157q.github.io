<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Just for noting</title><link>https://blog.m157q.tw/</link><description></description><lastBuildDate>Mon, 25 Nov 2013 08:22:00 +0800</lastBuildDate><item><title>CO Ch4 - The Processor</title><link>https://blog.m157q.tw/posts/2013/11/25/co-ch4-the-processor/</link><description>&lt;h1&gt;NCTUCS 2013-Fall Computer Organizaion by Professor Kai-Chiang Wu&lt;/h1&gt;
&lt;h1&gt;Ch4 - The Processor&lt;/h1&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CPU performance factor  &lt;ul&gt;
&lt;li&gt;Instrction count: Determined by ISA and compiler  &lt;/li&gt;
&lt;li&gt;CPI and Cycle Time: Determined by CPU hardware  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Two MIPS example  &lt;/li&gt;
&lt;li&gt;Simple subset, shows most aspects  &lt;ul&gt;
&lt;li&gt;Memory reference: lw, sw  &lt;/li&gt;
&lt;li&gt;Arithmetic/logical: add, sub, and, or, slt  &lt;/li&gt;
&lt;li&gt;Control transfer: beq, j  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Instruction Execution&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;PC, instruction memory, fetch instruction  &lt;/li&gt;
&lt;li&gt;Register numbers, register file, read registers  &lt;/li&gt;
&lt;li&gt;Depending on instruction class  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;CPU Overview&lt;/h1&gt;
&lt;p&gt;&lt;img alt="CPU Overview" src="/files/co-ch4-the-processor/cpu_overview.png" /&gt;  &lt;/p&gt;
&lt;h1&gt;Mutiplexers&lt;/h1&gt;
&lt;p&gt;You should use MUX to join wires together.  &lt;/p&gt;
&lt;h1&gt;Control&lt;/h1&gt;
&lt;p&gt;RegWrite, RegRead, MUX, MemRead, MemWrite, Zero, ALU operation, Branch  &lt;/p&gt;
&lt;h1&gt;Logic Design Basic&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Information encoded in binary  &lt;ul&gt;
&lt;li&gt;Low voltage = 0, High voltage = 1  &lt;/li&gt;
&lt;li&gt;One wire per bit  &lt;/li&gt;
&lt;li&gt;Multi-bit data encoded on multi-wire buses  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Combinational element  &lt;ul&gt;
&lt;li&gt;Operate on data  &lt;/li&gt;
&lt;li&gt;Output is a function of input  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;State (sequential) elements  &lt;ul&gt;
&lt;li&gt;Store information  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Combinational Elements&lt;/h1&gt;
&lt;p&gt;AND gate, Adder, MUX, ALU  &lt;/p&gt;
&lt;h1&gt;Sequential Elements&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Register: stores data in circuit  &lt;ul&gt;
&lt;li&gt;Uses a clock signal to determine when to update the stored value  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edge-triggered&lt;/strong&gt;: update when Clk changes from 0 to 1  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Performance Issues of Single Cycle Design&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Longest delay determines clock period  &lt;ul&gt;
&lt;li&gt;critical path: &lt;strong&gt;load instruction&lt;/strong&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Clocking Methodology&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Combinational logic transforms data during clock cycles  &lt;ul&gt;
&lt;li&gt;Between clock edges  &lt;/li&gt;
&lt;li&gt;Input from state elements, output to state element  &lt;/li&gt;
&lt;li&gt;Longest delay determines clock period  &lt;ul&gt;
&lt;li&gt;&lt;img alt="clock period" src="/files/co-ch4-the-processor/clock_period.png" /&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Building a Datapath&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Datapath&lt;/strong&gt;: Elements that process data and addresses in the CPU. ex: Reg, ALU, MUX, Mem  &lt;/p&gt;
&lt;h1&gt;Instruction Fetch&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Instruction Fetch" src="/files/co-ch4-the-processor/instruction_fetch.png" /&gt;  &lt;/p&gt;
&lt;h1&gt;R-Format Instructions&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Read two register operands  &lt;/li&gt;
&lt;li&gt;Perform arithmetic/logical operation  &lt;/li&gt;
&lt;li&gt;Write register result  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Load/Store Instructions&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Load: Read memory and update register  &lt;/li&gt;
&lt;li&gt;Store: Write register value to memory  &lt;/li&gt;
&lt;li&gt;Read register operands  &lt;/li&gt;
&lt;li&gt;Calculate address using &lt;strong&gt;16-bit&lt;/strong&gt; offset  &lt;ul&gt;
&lt;li&gt;Use ALU, but &lt;strong&gt;sign-extend&lt;/strong&gt; offset  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Hazards&lt;/h1&gt;
&lt;p&gt;Situations that prevent starting the next instruction in the next cycle  &lt;/p&gt;
&lt;h2&gt;Structure Hazards&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Conflict for use of a resource  &lt;/li&gt;
&lt;li&gt;In MIPS pipeline with a single memory  &lt;ul&gt;
&lt;li&gt;Load/store requires data access  &lt;/li&gt;
&lt;li&gt;Instruction fetch would have to stall for that cycle  &lt;ul&gt;
&lt;li&gt;Would cause a pipeline “bubble”  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pipelined datapaths require separate instruction/data memories or separate instruction/data caches  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data Hazards&lt;/h2&gt;
&lt;p&gt;An instruction depends on completion of data access by a previous instruction  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Forwarding (aka Bypassing)  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use result when it is computed  &lt;/li&gt;
&lt;li&gt;Don’t wait for it to be stored in a register  &lt;/li&gt;
&lt;li&gt;Requires extra connections in the datapath  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Load-Use Data Hazard  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can’t always avoid stalls by forwarding  &lt;ul&gt;
&lt;li&gt;If value not computed when needed  &lt;/li&gt;
&lt;li&gt;Can’t forward backward in time!  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Scheduling to Avoid Stalls  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reorder code to avoid use of load result in the next instruction  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Control Hazards&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Branch determines flow of control  &lt;ul&gt;
&lt;li&gt;Fetching next instruction depends on branch outcome  &lt;/li&gt;
&lt;li&gt;Pipeline can’t always fetch correct instruction  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;In MIPS pipeline&lt;br /&gt;
Need to compare registers and compute target early in the pipeline&lt;br /&gt;
Add hardware to do it in ID stage  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Stall on Branch  &lt;ul&gt;
&lt;li&gt;Wait until branch outcome determined before fetching next instruction  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Branch Prediction&lt;/h1&gt;
&lt;hr /&gt;
&lt;h1&gt;Pipeline Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pipelining improves performance by increasing instruction throughput  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executes multiple instructions in parallel  &lt;/li&gt;
&lt;li&gt;Each instruction has the same latency  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Subject to hazards  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Structure  &lt;/li&gt;
&lt;li&gt;Data  &lt;/li&gt;
&lt;li&gt;Control  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instruction set design affects complexity of pipeline implementation&lt;br /&gt;
￼￼  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;MIPS Pipelined Datapath&lt;/h1&gt;
&lt;p&gt;From left to right:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IF: Instruction fetch  &lt;/li&gt;
&lt;li&gt;ID: Instruction decode / register file read  &lt;/li&gt;
&lt;li&gt;EX: Execute / address calculation  &lt;/li&gt;
&lt;li&gt;MEM: Memory Access  &lt;/li&gt;
&lt;li&gt;WB: Write Back  &lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;left to right flow leads to hazards  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Pipeline Registers&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Pipeline Registers" src="/files/co-ch4-the-processor/pipeline_registers.png" /&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Need registers between stages to hold information produced in previous cycle.  &lt;/li&gt;
&lt;li&gt;IF and ID are in different instruction cycle, so we need registers.  &lt;/li&gt;
&lt;li&gt;If some results in this stage won't be used in the next stages, we don't need store those results in the pipeline registers.  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Pipeline Operation&lt;/h1&gt;
&lt;p&gt;Cycle-by-cycle flow of instructions through the pipelined datapath  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;“Single-clock-cycle”&lt;/strong&gt; pipeline diagram  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shows pipeline usage in a single cycle  &lt;/li&gt;
&lt;li&gt;Highlight resources used  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;“multi-clock-cycle”&lt;/strong&gt; pipeline diagram  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Graph of operation over time  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Corrected Datapath for Load&lt;/h1&gt;
&lt;p&gt;write address should be stored in the pipeline registers.&lt;br /&gt;
&lt;img alt="Corrected Datapath for Load" src="/files/co-ch4-the-processor/corrected_datapath_for_load.png" /&gt;  &lt;/p&gt;
&lt;h1&gt;Forwarding Paths&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Forwarding Unit  &lt;/li&gt;
&lt;li&gt;Control Unit  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Forwarding Conditions&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// EX hazard  
if (EX/MEM.RegWrite &amp;amp;&amp;amp; (EX/MEM.RegisterRd != 0))  
{  
    if (EX/MEM.RegisterRd = ID/EX.RegisterRs) ForwardA = 10;  
    if (EX/MEM.RegisterRd = ID/EX.RegisterRt) ForwardB = 10;  
}  

// MEM hazard  
if (MEM/WB.RegWrite &amp;amp;&amp;amp; (MEM/WB.RegisterRd != 0))  
{  
    if (MEM/WB.RegisterRd = ID/EX.RegisterRs) ForwardA = 01;  
    if (MEM/WB.RegisterRd = ID/EX.RegisterRt) ForwardB = 01;  
}  
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Double Data Hazard&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$2&lt;/span&gt;  
&lt;span class="no"&gt;add&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$3&lt;/span&gt;  
&lt;span class="no"&gt;add&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="no"&gt;$4&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Both hazards occur -&amp;gt; Want to use the most recent  &lt;/li&gt;
&lt;li&gt;Revise MEM hazard condition -&amp;gt; Only fwd if EX hazard condition isn’t true  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Revised Forwarding Condition&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// MEM hazard  
if (MEM/WB.RegWrite &amp;amp;&amp;amp; (MEM/WB.RegisterRd != 0))  
{  
    if ( !(EX/MEM.RegWrite &amp;amp;&amp;amp; (EX/MEM.RegisterRd != 0)  
    &amp;amp;&amp;amp; (EX/MEM.RegisterRd = ID/EX.RegisterRs)) )  
    {  
        if (MEM/WB.RegisterRd = ID/EX.RegisterRs) ForwardA = 01;  
    }  

    if ( !(EX/MEM.RegWrite &amp;amp;&amp;amp; (EX/MEM.RegisterRd != 0)  
    &amp;amp;&amp;amp; (EX/MEM.RegisterRd = ID/EX.RegisterRt)) )  
    {  
        if (MEM/WB.RegisterRd = ID/EX.RegisterRt) ForwardB = 01;  
    }  
}  
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Load-Use Hazard Detection&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Load-use hazard happens when  &lt;/span&gt;
&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EX&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MemRead&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt;  
&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EX&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegisterRt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;IF&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegisterRs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EX&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegisterRt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;IF&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegisterRt&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Check when using instruction is decoded in ID stage  &lt;/li&gt;
&lt;li&gt;If detected, stall and insert bubble  &lt;/li&gt;
&lt;li&gt;對一個 load word 的指令來說，我們要看的是他的 Rt  &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;How to Stall the Pipeline&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Force control values in ID/EX register to 0  &lt;ul&gt;
&lt;li&gt;EX, MEM and WB do nop (no-operation)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prevent update of PC and IF/ID register  &lt;ul&gt;
&lt;li&gt;Using instruction is decoded again  &lt;/li&gt;
&lt;li&gt;Following instruction is fetched again  &lt;/li&gt;
&lt;li&gt;1-cycle stall allows MEM to read data for lw  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Stalls and Performance&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Stalls reduce performance  &lt;ul&gt;
&lt;li&gt;But are required to get correct results  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compiler can arrange code to avoid hazards and stalls  &lt;ul&gt;
&lt;li&gt;Requires knowledge of the pipeline structure  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Reducing Branch Delay&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Move hardware to determine outcome to ID stage  &lt;ul&gt;
&lt;li&gt;Target address adder  &lt;/li&gt;
&lt;li&gt;Register comparator  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example: Branch taken  &lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;把 branch 決定的時間從 stage4 提早到 stage2,&lt;br /&gt;
在 stage2 才會知道這個 branch 是否會被 taken&lt;br /&gt;
決定的時間越早越好, 最早就是在 stage2 決定  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h1&gt;Data Hazards For Branches&lt;/h1&gt;
&lt;p&gt;If a comparison register is a destination of&lt;br /&gt;
+ 2nd or 3rd preceding ALU instruction&lt;br /&gt;
    + Can resolve using forwarding&lt;br /&gt;
+ preceding ALU instruction or 2nd preceding load instruction&lt;br /&gt;
    + Need 1 stall cycle&lt;br /&gt;
+ immediately preceding load instruction&lt;br /&gt;
    + Need 2 stall cycles  &lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Dynamic Branch Prediction&lt;/h1&gt;
&lt;hr /&gt;
&lt;h2&gt;NOTE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Intel Sandy Bridge 的 pipeline 約有 17 個 stage  &lt;/li&gt;
&lt;li&gt;Intel Sandy Bridge 和 Ivy Bridge 是以色列的研發團隊研發的  &lt;/li&gt;
&lt;li&gt;Haswell 是美國團隊研發的  &lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">m157q</dc:creator><pubDate>Mon, 25 Nov 2013 08:22:00 +0800</pubDate><guid isPermaLink="false">tag:blog.m157q.tw,2013-11-25:posts/2013/11/25/co-ch4-the-processor/</guid><category>Computer Organization</category></item><item><title>CO Ch5 - Large and Fast Exploiting Memory Hierarchy</title><link>https://blog.m157q.tw/posts/2013/11/25/co-ch5-large-and-fast-exploiting-memory-hierarchy/</link><description>&lt;h1&gt;NCTUCS 2013-Fall Computer Organizaion by Professor Kai-Chiang Wu&lt;/h1&gt;
&lt;h1&gt;Ch5 - Large and Fast Exploiting Memory Hierarchy&lt;/h1&gt;
&lt;h2&gt;Memory Technology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SRAM  &lt;/li&gt;
&lt;li&gt;DRAM  &lt;/li&gt;
&lt;li&gt;Williams-Kilburn tubes: 早期的 Memory 技術  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Memory Hierarchy Levels&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;教授：我去美國唸書的時候，教授都把 Cache Memory 直接簡寫成 $&lt;br /&gt;
所以之後我寫 $ 也是代表 Cache Memory  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;$ 在設計的時候通常都是跟 CPU 一起設計的，雖然他不在 CPU 裡面  &lt;/li&gt;
&lt;li&gt;CPU 透過 Mother board 上的 Bus 和 $ 交流資料  &lt;/li&gt;
&lt;li&gt;根據 Instruction Set 決定放在 $ 裡面的 Address 佔幾個 Word. (也就是設計 Block 的大小)  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Cache Memory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;除了 Register 以外，最接近 CPU 的 Memory  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Direct Mapped Cache&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;因為主記憶體比 Cache 大很多，無法直接全部對應到 Cache，所以必須有特殊的對應方法。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Direct mapped: only one choice  &lt;ul&gt;
&lt;li&gt;(Block address) modulo (#Blocks in cache)  &lt;ul&gt;
&lt;li&gt;Block 的位置除以 Cache 的 Block 總數後得到的餘數就是該 Block Address 要對應到的 Cache Address  &lt;/li&gt;
&lt;li&gt;其實沒有真的去作除法，直接看後面 3 個 bit (除以8得到的餘數，因為這裡的 cache 有 8 個)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;N-way associative: N choices  &lt;ul&gt;
&lt;li&gt;
&lt;h1&gt;Blocks is a power of 2&lt;/h1&gt;
&lt;/li&gt;
&lt;li&gt;Use low-order address bits  &lt;/li&gt;
&lt;li&gt;tag, index, offset(W.O., B.O.)  &lt;ul&gt;
&lt;li&gt;tag 代表了從 cache 如何找到該資料是存在哪個 block address  &lt;/li&gt;
&lt;li&gt;index 代表了該 block address 存在 cache 中的位置  &lt;/li&gt;
&lt;li&gt;offset 根據 block 大小不同而訂  &lt;ul&gt;
&lt;li&gt;W.O.: Word offset  &lt;/li&gt;
&lt;li&gt;B.O.: Byte offset  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Tags and Valid Bits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tag:  &lt;ul&gt;
&lt;li&gt;從 cache 如何找到該資料是存在哪個 block address  &lt;/li&gt;
&lt;li&gt;cache 也要存 tag，之後才知道要去找哪個 block  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Valid Bit  &lt;ul&gt;
&lt;li&gt;該 cache 無資料 =&amp;gt; 0  &lt;/li&gt;
&lt;li&gt;該 cache 有資料 =&amp;gt; 1  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Cache Example&lt;/h2&gt;
&lt;p&gt;見投影片 p.10 ~ p.15  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;22 =&amp;gt; 10110  &lt;ul&gt;
&lt;li&gt;tag =&amp;gt; 10  &lt;/li&gt;
&lt;li&gt;index =&amp;gt; 110  &lt;/li&gt;
&lt;li&gt;Hit/miss  &lt;ul&gt;
&lt;li&gt;要找的東西的 tag 和 index 有沒有已經存在 cache 中(tag 和 index 皆相同)  &lt;/li&gt;
&lt;li&gt;沒的話就是 miss, 有的話就是 hit  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Address Subdivision&lt;/h2&gt;
&lt;p&gt;見 p.16  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;byte address  &lt;/li&gt;
&lt;li&gt;2^n blocks  &lt;/li&gt;
&lt;li&gt;block data size 2^m words  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;聽不太懂  &lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Address Translation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Virtual Memory  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Page Fault Penalty&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Page Fault means that the data we find is not in the phyiscal address but disk storage.  &lt;/li&gt;
&lt;li&gt;Virtual Memory 經過 page table 查找後，無法在 Physical Address 找到，則為 Page Fault。  &lt;/li&gt;
&lt;li&gt;Page Fault 類似 cache 裡面的 miss  &lt;/li&gt;
&lt;li&gt;Millions of clock cycles (比 cache 的 panelty 大)  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Page Tables&lt;/h2&gt;
&lt;p&gt;p.51  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Virtual Address (VA) -&amp;gt; Page Table (PT) -&amp;gt; Physical Address (PA)  &lt;/li&gt;
&lt;li&gt;page table entries (PTEs)  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;page table register&lt;/strong&gt; in CPU points to page table in physical memory  &lt;/li&gt;
&lt;li&gt;status bits  &lt;ul&gt;
&lt;li&gt;referenced  &lt;/li&gt;
&lt;li&gt;dirty - 先標記起來，之後讀寫  &lt;/li&gt;
&lt;li&gt;valid - 是不是真的有資料  &lt;ul&gt;
&lt;li&gt;If valid bit is zero, the page fault occurs and the data is not in the physical address but disk storage.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Every Page Table entry is 4 bytes.  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Translation Using a Page Table&lt;/h2&gt;
&lt;p&gt;p.52  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We can know the amount of page offset by knowing 4 bytes per page table entry.  &lt;/li&gt;
&lt;li&gt;Virtual address(32 bits) = Virtual page number(32-x bits) + Page Offset(x bits)  &lt;ul&gt;
&lt;li&gt;x depends on the size of the page.  &lt;/li&gt;
&lt;li&gt;x is usually 12bits. (4KB per page)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Replacement and Writes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;use least-recently used (LRU) to reduce page fault rate.  &lt;/li&gt;
&lt;li&gt;use dirty bit in PTE set when page is written to reduce the access to main memory.  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Page Table Problems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;page table is &lt;strong&gt;too big&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;Access to page table is &lt;strong&gt;too slow&lt;/strong&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Fast Translation Using a TLB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VA -&amp;gt; PT (in main memory) / TLB (in CPU for usually used) -&amp;gt; PA  &lt;/li&gt;
&lt;li&gt;Translation Look-aside Buffer (TLB)  &lt;ul&gt;
&lt;li&gt;use a fast cache of PTEs within the CPU  &lt;/li&gt;
&lt;li&gt;access to page tables has good &lt;strong&gt;time locality&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;Extra misses occured when query in TLB failed. (queried data is in PT)  &lt;/li&gt;
&lt;li&gt;Those Misses could be handled by hardware or software  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">m157q</dc:creator><pubDate>Mon, 25 Nov 2013 07:53:00 +0800</pubDate><guid isPermaLink="false">tag:blog.m157q.tw,2013-11-25:posts/2013/11/25/co-ch5-large-and-fast-exploiting-memory-hierarchy/</guid><category>Computer Organization</category></item></channel></rss>