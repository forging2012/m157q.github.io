<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Just for noting</title><link href="https://blog.m157q.tw/" rel="alternate"></link><link href="https://blog.m157q.tw/feeds/tag.dnn.atom.xml" rel="self"></link><id>https://blog.m157q.tw/</id><updated>2017-08-13T17:08:45+08:00</updated><entry><title>台灣資料科學年會之系列活動：手把手的深度學習實務</title><link href="https://blog.m157q.tw/posts/2017/08/13/deep-learning-hands-on-step-by-step-datasci-tw/" rel="alternate"></link><published>2017-08-13T17:08:45+08:00</published><updated>2017-08-13T17:08:45+08:00</updated><author><name>m157q</name></author><id>tag:blog.m157q.tw,2017-08-13:posts/2017/08/13/deep-learning-hands-on-step-by-step-datasci-tw/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://foundation.datasci.tw/step-by-step-dl-170813/"&gt;http://foundation.datasci.tw/step-by-step-dl-170813/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://drive.google.com/file/d/0B9cCeTKOkfWIbWtjdWJaRl9YRmM/view?usp=sharing"&gt;Slides&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;六步完模 – 建立深度學習模型&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;決定 hidden layers 層數與其中的 neurons 數量  &lt;/li&gt;
&lt;li&gt;決定該層使用的 activation function  &lt;/li&gt;
&lt;li&gt;決定模型的 loss function  &lt;/li&gt;
&lt;li&gt;決定 optimizer  &lt;ul&gt;
&lt;li&gt;Parameters: learning rate, momentum, decay  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;編譯模型 (Compile model)  &lt;/li&gt;
&lt;li&gt;開始訓練囉!(Fit model)  &lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h3&gt;關於 &lt;code&gt;validation_split&lt;/code&gt; 要注意的小地方&lt;/h3&gt;
&lt;p&gt;用 Keras 的 &lt;code&gt;validation_split&lt;/code&gt; 之前要記得把資料先弄亂，&lt;br /&gt;
因為它會從資料的最尾端開始取，&lt;br /&gt;
如果沒有弄亂的話切出來的資料 bias 會很大。&lt;br /&gt;
可以使用 &lt;code&gt;np.shuffle&lt;/code&gt; 來弄亂  &lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Functional API&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Why “Functional API” ?  &lt;ul&gt;
&lt;li&gt;All layers and models are callable (like function call)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;  
&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;  
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;+ 類似 f(x) 的寫法  
    + Dense(10) == f  
    + input == x  
+ 好處是可以 assign 給自己後再用 for loop 很快建非常多層 layer，不用一直用 `model.add`  
+ Easy to manipulate various inpout sources
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x1 = input(shape=(10,))  
y1 = Dense(100)(x1)  

x2 = input(shape=(20,))  
new_x2 = keras.layers.concatenate([y1,x2])  
output = Dense(200)(new_x2)  

Model = Model(inputs=[x1,x2],outputs=[output])  
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;Loss function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;為什麼 Cross-entropy 比 Squared error 好？  &lt;ul&gt;
&lt;li&gt;Cross-entropy 的 Gradient 比較大，學習速度比較快。  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.complex-systems.com/pdf/02-6-1.pdf"&gt;The error surface of logarithmic functions is steeper than&lt;br /&gt;
that of quadratic functions.&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How to select Loss function  &lt;ul&gt;
&lt;li&gt;Classification 常用 cross-entropy  &lt;ul&gt;
&lt;li&gt;搭配 softmax 當作 output layer 的 activation function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Regression 常用 mean absolute/squared error  &lt;/li&gt;
&lt;li&gt;對特定問題定義 loss function  &lt;ul&gt;
&lt;li&gt;Unbalanced dataset, class 0 : class 1 = 99 : 1  &lt;ul&gt;
&lt;li&gt;Class 1 做錯的話，給它 penalty 99  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-defined loss function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Learning Rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;觀察 Loss，如果有振盪的話，代表 learning rate 可能太大  &lt;/li&gt;
&lt;li&gt;觀察 Loss，下降的太緩慢的話，代表 learning rate 可能太小  &lt;/li&gt;
&lt;li&gt;選擇適合的 learning rate 對於 training model 會是很大的影響  &lt;/li&gt;
&lt;li&gt;通常不會大於 0.1  &lt;/li&gt;
&lt;li&gt;一次調整一個數量級  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Activation Function&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Activation Function 可能是最重要的  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Sigmoid 介於 0~1 之間  &lt;/li&gt;
&lt;li&gt;Tanh, Softsign 介於 -1~1 之間  &lt;/li&gt;
&lt;li&gt;值域是有限制的  &lt;ul&gt;
&lt;li&gt;Input 過大或過小影響其實不大  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Derivatives of Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Input 過大或過小時，Gradient 太小，學習就會很慢  &lt;/li&gt;
&lt;li&gt;所以通常太深的 model 不建議用這 3 個 Activation Function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Drawbacks of Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Vanishing gradient problem  &lt;ul&gt;
&lt;li&gt;原因: input 被壓縮到一個相對很小的output range  &lt;/li&gt;
&lt;li&gt;結果: 很大的 input 變化只能產生很小的 output 變化 =&amp;gt; Gradient 小 =&amp;gt; 無法有效地學習  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特別不適用於深的深度學習模型  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ReLU, Softplus  &lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;在 TensorFlow 上用 Softplus 好像會遇到一些問題  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Derivatives of ReLU, Softplus  &lt;ul&gt;
&lt;li&gt;ReLU 在輸入小於零時, gradient 等於零,會有問題嗎?  &lt;ul&gt;
&lt;li&gt;小於 0 的時候可能就不學習了，所以有人提出了 Leaky ReLU  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Leaky ReLU  &lt;ul&gt;
&lt;li&gt;Allow a small gradient while the input to activation function smaller than 0  &lt;/li&gt;
&lt;li&gt;在 input &amp;lt; 0 時，還是給他一點些微的斜率  &lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;在用 ReLU 的時候 Learning rate 可能要用小一點，效果會比較好。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Optimizer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SGD – Stochastic Gradient Descent  &lt;ul&gt;
&lt;li&gt;Stochastic gradient descent  &lt;/li&gt;
&lt;li&gt;支援 momentum, learning rate decay, Nesterov momentum  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizer.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Momentum 的影響  &lt;ul&gt;
&lt;li&gt;無 momentum: &lt;code&gt;update = -lr*gradient&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;有 momentum: &lt;code&gt;update = -lr*gradient + m*last_update&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning rate decay after update once  &lt;ul&gt;
&lt;li&gt;屬於 &lt;code&gt;1/t decay =&amp;gt; lr = lr / (1 + decay*t)&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;t: number of done updates  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Momentum vs Nesterov Momentum  &lt;ul&gt;
&lt;li&gt;Momentum  &lt;ul&gt;
&lt;li&gt;先算 gradient  &lt;/li&gt;
&lt;li&gt;加上 momentum  &lt;/li&gt;
&lt;li&gt;更新  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nesterov Momentum  &lt;ul&gt;
&lt;li&gt;加上 momentum  &lt;/li&gt;
&lt;li&gt;再算 gradient  &lt;/li&gt;
&lt;li&gt;更新  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;兩者出來的效果沒有太大的差別，沒有誰比較好，只是聽到有人用 Nesterov 的時候要知道差別。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adagrad – Adaptive Learning Rate  &lt;ul&gt;
&lt;li&gt;因材施教:每個參數都有不同的 learning rate  &lt;/li&gt;
&lt;li&gt;根據之前所有 gradient 的 root mean square 修改  &lt;/li&gt;
&lt;li&gt;Feature scales 不同,需要不同的 learning rates  &lt;/li&gt;
&lt;li&gt;每個 weight 收斂的速度不一致  &lt;ul&gt;
&lt;li&gt;但 learning rate 沒有隨著減少的話  bumpy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;根據之前所有 gradient 的 root mean square 修改  &lt;/li&gt;
&lt;li&gt;老馬識途,參考之前的經驗修正現在的步伐  &lt;/li&gt;
&lt;li&gt;不完全相信當下的 gradient  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RMSprop – Similar with Adagrad  &lt;ul&gt;
&lt;li&gt;另一種參考過去 gradient 的方式  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adagrad 不管多久之前的經驗都把其權重視為相同的，RMSprop 就是針對這部份做改進，愈久之前的經驗其權重會變得愈低。  &lt;/li&gt;
&lt;li&gt;這個 Activation 是作者在 Coursera 授課時提出的，沒有論文，所以大家在論文使用這個 activation function 的時候都會 cite 那個 coursera 課程的網址，而且還不少人用的 XDDD  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adam – Similar with RMSprop + Momentum  &lt;ul&gt;
&lt;li&gt;Close to RMSprop + Momentum  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1412.6980v8.pdf"&gt;ADAM: A Method For Stochastic Optimization&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;In practice, 不改參數也會做得很好  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizer.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nadam – Adam + Nesterov Momentum  &lt;/li&gt;
&lt;li&gt;How to select Optimizer  &lt;ul&gt;
&lt;li&gt;一般的起手式: Adam  &lt;ul&gt;
&lt;li&gt;Adaptive learning rate for every weights  &lt;/li&gt;
&lt;li&gt;Momentum included  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Keras 推薦 RNN 使用 RMSProp  &lt;ul&gt;
&lt;li&gt;在訓練 RNN 需要注意 explosive gradient 的問題 =&amp;gt; clip gradient 的暴力美學  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RMSProp 與 Adam 的戰爭仍在延燒  &lt;ul&gt;
&lt;li&gt;各有千秋  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;處理 Overfitting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Regularization  &lt;ul&gt;
&lt;li&gt;限制 weights 的大小讓 output 曲線比較平滑  &lt;/li&gt;
&lt;li&gt;Weight 較小，input 的差異對 output 產生的影響比較沒有那麼大  &lt;/li&gt;
&lt;li&gt;α (Regularizer) 是用來調整 regularization 的比重  &lt;ul&gt;
&lt;li&gt;避免顧此失彼 (降低 weights 的大小而犧牲模型準確性)&lt;br /&gt;
避免顧此失彼 (降低 weights 的大小而犧牲模型準確性)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;L1 and L2 Regularizers  &lt;ul&gt;
&lt;li&gt;L1 norm: Sum of absolute values  &lt;/li&gt;
&lt;li&gt;L2 norm: Root mean square of absolute values  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Early Stopping  &lt;ul&gt;
&lt;li&gt;希望在 Model overfitting 之前就停止 training  &lt;/li&gt;
&lt;li&gt;假如可以停在 loss 最低的點的話就好了  &lt;/li&gt;
&lt;li&gt;Early Stopping in Keras  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;from keras.callbacks import EarlyStopping&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;early_stopping=EarlyStopping(monitor='val_loss', patience=3)&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;monitor: 要監控的 performance index  &lt;/li&gt;
&lt;li&gt;patience: 可以容忍連續幾次的不思長進  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dropout  &lt;ul&gt;
&lt;li&gt;What is Dropout  &lt;ul&gt;
&lt;li&gt;原本為 neurons 跟 neurons 之間為 fully connected  &lt;/li&gt;
&lt;li&gt;在訓練過程中,隨機拿掉一些連結 (weight 設為0)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;會造成 training performance 變差  &lt;ul&gt;
&lt;li&gt;Error 變大 =&amp;gt; 每個 neuron 修正得越多 =&amp;gt; 做得越好  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Implications  &lt;ul&gt;
&lt;li&gt;增加訓練的難度，在真正的考驗時爆發  &lt;/li&gt;
&lt;li&gt;Dropout 可視為一種終極的 ensemble 方法，N 個 weights 會有 2^N 種 network structures  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通常只加在 hidden layer，不會加在 output layer，因為影響太大了，除非 output layer 的 dimension 很大。  &lt;/li&gt;
&lt;li&gt;注意事項  &lt;ul&gt;
&lt;li&gt;「不要一開始就加入 Dropout」*3  &lt;/li&gt;
&lt;li&gt;確定有遇到 Overfitting 再加 Dropout  &lt;/li&gt;
&lt;li&gt;Dropout 會讓 training performance 變差  &lt;/li&gt;
&lt;li&gt;確定 performance 夠好再加 Dropout，不然 Performance 變低，就算解掉了 Overfitting，出來的結果也沒啥用。  &lt;/li&gt;
&lt;li&gt;Dropout 是在避免 overfitting，不是萬靈丹  &lt;/li&gt;
&lt;li&gt;參數少時，regularization  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Callbacks: 善用 Callbacks 幫助你躺著 train models&lt;/h3&gt;
&lt;h4&gt;Callback Class&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Callbacks&lt;/span&gt;  

&lt;span class="n"&gt;Class&lt;/span&gt; &lt;span class="n"&gt;LossHistory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Callbacks&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_train_begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_batch_end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;acc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;val_acc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  

    &lt;span class="n"&gt;loss_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LossHistory&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Callback 的時機&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;on_train_begin  &lt;/li&gt;
&lt;li&gt;on_train_end  &lt;/li&gt;
&lt;li&gt;on_batch_begin  &lt;/li&gt;
&lt;li&gt;on_batch_end  &lt;/li&gt;
&lt;li&gt;on_epoch_begin  &lt;/li&gt;
&lt;li&gt;on_epoch_end  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;LearningRateScheduler&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LearningRateScheduler&lt;/span&gt;  

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;step_decay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  
    &lt;span class="n"&gt;initial_lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;  
    &lt;span class="n"&gt;lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initial_lrate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.999&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lrate&lt;/span&gt;  

&lt;span class="n"&gt;Lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LearningRateScheduler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_decay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;ModelCheckpoint&lt;/h4&gt;
&lt;p&gt;超級好用  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ModelCheckpoint&lt;/span&gt;  

&lt;span class="n"&gt;checkpoint&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ModelCheckpoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;  
    &lt;span class="s1"&gt;&amp;#39;model.h5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;monitor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;verbose&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;save_best_only&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;min&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mode&lt;/code&gt; 可以設定成 &lt;code&gt;'auto'&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;在 &lt;code&gt;model.fit&lt;/code&gt; 時加入 Callbacks&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;history = model.fit(  
    X_train,  
    Y_train,  
    batch_size=16,  
    verbose=0,  
    epochs=30,  
    shuffle=True,  
    validation_split=0.1,  
    callbacks=[  
        early_stopping,  
        loss_history,  
        lrate,  
        checkpoint,  
    ],  
)  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;但也不要一開始就加一堆 callbacks&lt;br /&gt;
尤其是 Learning Rate Scheduler&lt;br /&gt;
不好的 Learning Rate Scheduler 會導致不好的結果  &lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Semi-supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;解決的問題  &lt;ul&gt;
&lt;li&gt;收集到的標籤遠少於實際擁有的資料量  &lt;ul&gt;
&lt;li&gt;該如何增加 label 呢?  &lt;ul&gt;
&lt;li&gt;Crowd-sourcing  &lt;/li&gt;
&lt;li&gt;Semi-supervised learning  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;步驟  &lt;ul&gt;
&lt;li&gt;先用 labeled dataset to train model  &lt;ul&gt;
&lt;li&gt;至少 train 到一定的程度 (良心事業)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;拿 unlabeled dataset 來測試，挑出預測好的 unlabeled dataset  &lt;/li&gt;
&lt;li&gt;假設預測的都是對的 (unlabeled =&amp;gt; labeled)  &lt;ul&gt;
&lt;li&gt;有更多 labeled dataset 了!  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Repeat the above steps  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意事項  &lt;ul&gt;
&lt;li&gt;加入品質不佳的 labels 反而會讓 model 變差  &lt;/li&gt;
&lt;li&gt;要注意加入的資料有沒有偏差的情況，否則最後 train 出來的 model 會變成只偏向某一類的結果  &lt;/li&gt;
&lt;li&gt;慎選要加入的 samples  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Transfer Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;“transfer”: use the knowledge learned from task A to tackle another task B  &lt;/li&gt;
&lt;li&gt;Use as Fixed Feature Extractor  &lt;ul&gt;
&lt;li&gt;A known model, like VGG, trained on ImageNet  &lt;/li&gt;
&lt;li&gt;ImageNet: 10 millions images with labels  &lt;/li&gt;
&lt;li&gt;取某一個 layer output 當作 feature vectors  &lt;/li&gt;
&lt;li&gt;Train a classifier based on the features extracted by a known model  &lt;/li&gt;
&lt;li&gt;當資料很少的時候這招很好用  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use as Initialization  &lt;ul&gt;
&lt;li&gt;Initialize your net by the weights of a known model  &lt;/li&gt;
&lt;li&gt;Use your dataset to further train your model  &lt;/li&gt;
&lt;li&gt;Fine-tuning the known model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Short Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Unlabeled data (lack of y) =&amp;gt; Semi-supervised learning  &lt;/li&gt;
&lt;li&gt;Insufficient data (lack of both x and y) =&amp;gt; Transfer learning (focus on layer transfer)  &lt;ul&gt;
&lt;li&gt;Use as fixed feature extractor  &lt;/li&gt;
&lt;li&gt;Use as initialization  &lt;/li&gt;
&lt;li&gt;Resources: https://keras.io/applications/  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Convolutional Neural Network (CNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;只要 input 是二維以上，且要找特定的 Pattern 的話，就可以用 CNN，不侷限於影像。  &lt;/li&gt;
&lt;li&gt;DNN 的輸入是一維的向量,那二維的矩陣呢? 例如：圖形資料  &lt;/li&gt;
&lt;li&gt;將圖形轉換成一維向量  &lt;ul&gt;
&lt;li&gt;Weight 數過多,造成 training 所需時間太長  &lt;/li&gt;
&lt;li&gt;左上的圖形跟右下的圖形真的有關係嗎?  &lt;ul&gt;
&lt;li&gt;只要留下重要的地方就好了，不需要全部的 neuron 都連接起來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;圖的構成  &lt;ul&gt;
&lt;li&gt;線條 (Line Segment)  &lt;/li&gt;
&lt;li&gt;圖案 (Pattern)  &lt;/li&gt;
&lt;li&gt;物件 (Object)  &lt;/li&gt;
&lt;li&gt;場景 (Scene)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;辨識一個物件只需要幾個特定的圖案  &lt;/li&gt;
&lt;li&gt;Property  &lt;ul&gt;
&lt;li&gt;What: 圖案的類型  &lt;/li&gt;
&lt;li&gt;Where: 重複的圖案可能出現在很多不同的地方  &lt;/li&gt;
&lt;li&gt;Size: 大小的變化並沒有太多的影響  &lt;ul&gt;
&lt;li&gt;Subsampling  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolution in Computer Vision  &lt;ul&gt;
&lt;li&gt;Common applications  &lt;ul&gt;
&lt;li&gt;模糊化、銳利化、浮雕  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://setosa.io/ev/image-kernels/"&gt;http://setosa.io/ev/image-kernels/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adding each pixel and its local neighbors which are weighted by a filter (kernel)  &lt;/li&gt;
&lt;li&gt;Perform this convolution process to every pixels  &lt;ul&gt;
&lt;li&gt;當 pixel 的 value 高的時候，代表 pattern 有出現在該位置  &lt;/li&gt;
&lt;li&gt;當 pixel 的 value 低的時候，代表 pattern 沒有出現在該位置  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A filter could be seen as a pattern  &lt;/li&gt;
&lt;li&gt;常拿來做 Edge Detection  &lt;ul&gt;
&lt;li&gt;edge = 亮度變化大的地方  &lt;/li&gt;
&lt;li&gt;凸顯兩像素之間的差異  &lt;/li&gt;
&lt;li&gt;如果覺得 gap 太小的話，可以再乘上一個 constant 將其凸顯出來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相鄰兩像素值差異越大,convolution 後新像素絕對值越大  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolutional Layer  &lt;ul&gt;
&lt;li&gt;Convolution 執行越多次影像越小  &lt;/li&gt;
&lt;li&gt;Hyper-parameters of Convolutional Layer  &lt;ul&gt;
&lt;li&gt;Filter size  &lt;/li&gt;
&lt;li&gt;Zero-padding  &lt;ul&gt;
&lt;li&gt;Add additional zeros at the border of image  &lt;/li&gt;
&lt;li&gt;Zero-padding 不會影響 convolution 的性質  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stride  &lt;ul&gt;
&lt;li&gt;Shrink the output of the convolutional layer  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Depth (total number of filters)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pooling Layer  &lt;ul&gt;
&lt;li&gt;Why do we need pooling layers?  &lt;ul&gt;
&lt;li&gt;Reduce the number of weights  &lt;/li&gt;
&lt;li&gt;Prevent overfitting  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Max pooling  &lt;ul&gt;
&lt;li&gt;Consider the existence of patterns in each region  &lt;/li&gt;
&lt;li&gt;在作 Classification 上用得到  &lt;ul&gt;
&lt;li&gt;因為我們在做分類的時候會找尋特定的 pattern 是否有出現在該圖片中  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;但是會有些資訊喪失  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Average Pooling  &lt;ul&gt;
&lt;li&gt;因為是取平均的關係，所以出來的結果很高的話，代表該區域的值都很高，所以 pattern 出現在該位置的可能性也很高  &lt;/li&gt;
&lt;li&gt;用來找尋一再重複出現的 pattern  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A CNN Example (Object Recognition)  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/convolutional-networks/"&gt;CS321n, Standford&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Filters Visualization  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.rsipvision.com/exploring-deep-learning/"&gt;RSIP VISION&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;CNN in Keras&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Concatenate Datasets by Numpy Functions  &lt;ul&gt;
&lt;li&gt;hstack, dim(6,)  &lt;ul&gt;
&lt;li&gt;[1, 2, 3, 4, 5, 6], Labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vstack, dim(2,3)  &lt;ul&gt;
&lt;li&gt;[[1, 2, 3], [4, 5, 6]], Pixel values  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;dstack, dim(1, 3, 2)  &lt;ul&gt;
&lt;li&gt;[[1, 2], [3, 4], [5, 6]], Dimensions  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Concatenating Input Datasets  &lt;ul&gt;
&lt;li&gt;利用 vstack 連接 pixel values;用 hstack 連接 labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reshape the Training/Testing Inputs  &lt;ul&gt;
&lt;li&gt;利用影像的長寬資訊先將 RGB 影像分開,再利用 reshape 函式將一維向量轉換為二維矩陣,最後用 dstack 將 RGB image 連接成三維陣列  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Saving Each Data as Image  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;scipy.misc.imsave&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;PIL.Image&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building Your Own CNN Model  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;#39;&amp;#39;&amp;#39;CNN model&amp;#39;&amp;#39;&amp;#39;  

# CNN  
model = Sequential()  
model.add(  
Convolution2D(  
    32,  
    3,  
    3,  
    border_mode=&amp;#39;same&amp;#39;,  # 有做 zero-padding 的意思  
    input_shape=X_train[0].shape)  
)  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(Convolution2D(32, 3, 3))  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(MaxPooling2D(pool_size=(2, 2)))  
model.add(Dropout(0.2))  

model.add(Flatten())  

# DNN  
model.add(Dense(512))  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(Dropout(0.5))  
model.add(Dense(10))  
model.add(Activation(&amp;#39;softmax&amp;#39;))  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Tips for Setting Hyper-parameters  &lt;ul&gt;
&lt;li&gt;影像的大小須要能夠被 2 整除數次  &lt;/li&gt;
&lt;li&gt;Convolutional Layer  &lt;ul&gt;
&lt;li&gt;比起使用一個 size 較大的 filter (7x7),可以先嘗試連續使用數個 size 小的 filter (3x3)  &lt;/li&gt;
&lt;li&gt;Stride 的值與 filter size 相關,通常 stride ≤ (W_f - 1)/2  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Very deep CNN model (16+ Layers) 多使用 3x3 filter 與 stride 1  &lt;/li&gt;
&lt;li&gt;Zero-padding 與 pooling layer 是選擇性的結構  &lt;/li&gt;
&lt;li&gt;Zero-padding 的使用取決於是否要保留邊界的資訊  &lt;/li&gt;
&lt;li&gt;Pooling layer 旨在避免 overfitting 與降低 weights 的數量, 但也減少影像所包含資訊,一般不會大於 3x3  &lt;ul&gt;
&lt;li&gt;像圍棋就不太適合用 Pooling，因為可能會失真。所以 AlphaGo 其實只有用 Convolutional Layer，沒有用 Pooling Layer。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;嘗試修改有不錯效能的 model,會比建立一個全新的模型容易收斂,且 model weights 越多越難 tune 出好的參數  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Deep Learning Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://visualqa.org/"&gt;Visual Question Answering&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Video Captioning  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1701.00160.pdf"&gt;Text-To-Image&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1511.06434.pdf"&gt;Vector Arithmetic for Visual Concepts&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Go Deeper in Deep Learning  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/"&gt;Neural Networks and Deep Learning&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.iro.umontreal.ca/~bengioy/dlbook/"&gt;Deep Learning&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html"&gt;Course: Machine learning and having it deep and structured&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/"&gt;Keras documentation&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fchollet/keras"&gt;Keras GitHub&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ"&gt;台大電機李宏毅教授 Youtube 頻道&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.stanford.edu/"&gt;Convolutional Neural Networks for Visual Recognition cs231n&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果 feature 數量不夠的話，可以做些簡單的運算增加 feature 的量，尤其是已經知道這樣的 feature 會對 training 有幫助的話。  &lt;/li&gt;
&lt;li&gt;Keras model 相關的操作  &lt;ul&gt;
&lt;li&gt;用 &lt;code&gt;model.save()&lt;/code&gt; 來將訓練好的 model 存起來  &lt;/li&gt;
&lt;li&gt;之後可用 &lt;code&gt;keras.models.load_model()&lt;/code&gt; 來讀入已經訓練好的 model  &lt;/li&gt;
&lt;li&gt;讀入之後可再用 &lt;code&gt;model.summary()&lt;/code&gt; 來確認一下 model 的資訊  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.layers[0].get_weights()&lt;/code&gt; 可以得到此 model 第 1 層的 weights  &lt;/li&gt;
&lt;li&gt;用 &lt;code&gt;model.predict()&lt;/code&gt; 來預測結果  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當資料太大無法一次讀進來時，可以用 &lt;a href="https://keras.io/models/sequential/#fit_generator"&gt;Fit Generator&lt;/a&gt;。  &lt;ul&gt;
&lt;li&gt;需要自己撰寫一個 generator  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Deep Learning"></category><category term="Keras"></category><category term="CNN"></category><category term="DNN"></category></entry><entry><title>台灣資料科學年會之系列活動：深入淺出深度學習 (Dive into Deep Learning)</title><link href="https://blog.m157q.tw/posts/2017/08/12/dive-into-deep-learning-datasci-tw/" rel="alternate"></link><published>2017-08-12T17:02:14+08:00</published><updated>2017-08-12T17:02:14+08:00</updated><author><name>m157q</name></author><id>tag:blog.m157q.tw,2017-08-12:posts/2017/08/12/dive-into-deep-learning-datasci-tw/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;Links  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://foundation.datasci.tw/dive-deep-learning-170812/"&gt;http://foundation.datasci.tw/dive-deep-learning-170812/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://dsc.kktix.cc/events/series-events-081213"&gt;https://dsc.kktix.cc/events/series-events-081213&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slides  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://drive.google.com/file/d/0B9cCeTKOkfWIVF9CeXpXaC1lUVk/view?usp=sharing"&gt;DiveDL_0326_v1.pdf&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Regression&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;適用場景  &lt;ul&gt;
&lt;li&gt;股票預測  &lt;/li&gt;
&lt;li&gt;無人車方向調整  &lt;/li&gt;
&lt;li&gt;推薦系統  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;步驟  &lt;ul&gt;
&lt;li&gt;決定 Model  &lt;/li&gt;
&lt;li&gt;評估所使用的函數夠不夠好  &lt;ul&gt;
&lt;li&gt;Loss Funciton  &lt;ul&gt;
&lt;li&gt;output 分數低，代表 loss 少，所以比較好。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;找出表現最好的 Loss Function  &lt;ul&gt;
&lt;li&gt;利用 Gradient Descent 來找  &lt;ul&gt;
&lt;li&gt;縱軸為 L 的 output，橫軸為 w  &lt;/li&gt;
&lt;li&gt;L 對 w 偏微分，取得其切線斜率  &lt;/li&gt;
&lt;li&gt;切線斜率為負時，增加 w，來取得較低的 L output  &lt;/li&gt;
&lt;li&gt;切線斜率為正時，減少 w，來取得較低的 L output  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;非 Linear 的話，會出現 Local optimal 和 Global optimal 的狀況  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;得到 Model  &lt;/li&gt;
&lt;li&gt;Model Generalization  &lt;ul&gt;
&lt;li&gt;嘗試不同的 Model  &lt;/li&gt;
&lt;li&gt;太過複雜的 Model 會出現 Overfitting 的狀況  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Classification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;分類  &lt;ul&gt;
&lt;li&gt;Binary Classification  &lt;ul&gt;
&lt;li&gt;Yes/No  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;Spam Filtering  &lt;ul&gt;
&lt;li&gt;把 email 裡面的詞都當作一個 feature，透過 trained model 來得到 Boolean 的結果。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-Class Classification  &lt;ul&gt;
&lt;li&gt;判斷是哪個種類  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;餵入圖片，判斷是哪種動物  &lt;/li&gt;
&lt;li&gt;判斷新聞是屬於哪一種主題  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Introduction to ML &amp;amp; DL&lt;/h1&gt;
&lt;h2&gt;Basic Deep Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stacked function learned by machine  &lt;/li&gt;
&lt;li&gt;Deep Learning 三步驟  &lt;ul&gt;
&lt;li&gt;Define a set of function  &lt;/li&gt;
&lt;li&gt;Godness of function  &lt;/li&gt;
&lt;li&gt;pick the best function  &lt;/li&gt;
&lt;li&gt;(和 ML 很像）  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 1: Define a set of function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Neural Network  &lt;ul&gt;
&lt;li&gt;Neuron: input, weights, bias, Activation function  &lt;/li&gt;
&lt;li&gt;將多個 Neuron 組合在一起，形成 Neuron Network  &lt;/li&gt;
&lt;li&gt;愈多層的話需要調整的參數越多  &lt;/li&gt;
&lt;li&gt;不同的 Connections 可以形成不同的 Neural Network  &lt;ul&gt;
&lt;li&gt;Fully-Connected Feedforward Network  &lt;ul&gt;
&lt;li&gt;每一個 Neuron 都跟前一個相連，會一直把數值傳下去。  &lt;/li&gt;
&lt;li&gt;Input Layer + Hidden Layers + Output Layer  &lt;/li&gt;
&lt;li&gt;"Deep" means multiple hidden layers  &lt;ul&gt;
&lt;li&gt;DNN 的 hidden layers 至少要大於 2  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why Deep?  &lt;ul&gt;
&lt;li&gt;Fat + Shallow vs Thin + Deep  &lt;ul&gt;
&lt;li&gt;在數學上被證明是可以用一層很寬的 layer 來取代多層的 layers，但為什麼不用？  &lt;/li&gt;
&lt;li&gt;因為只用一層的話會需要使用到更多的 Neurons。（可以用類似 Logic Gates 簡化的方式來想）  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Examples  &lt;ul&gt;
&lt;li&gt;AlexNet (2012): 8 layers, 16.4%  &lt;/li&gt;
&lt;li&gt;VGG (2014): 19 layers, 7.3%  &lt;/li&gt;
&lt;li&gt;GoogleNet (2014): 22 layers, 6.7%  &lt;/li&gt;
&lt;li&gt;Residual Net (2015): 152 layers, 3.57%  &lt;ul&gt;
&lt;li&gt;人類自己把所有的 training data 看完後下去做測試，error rate 大概是 4~5%  &lt;/li&gt;
&lt;li&gt;首度超越人類  &lt;/li&gt;
&lt;li&gt;因為疊了很多層，所以可能有些資訊會在傳遞中遺失，所以使用了 Special structure，會把一些一開始就學到的很重要 information 直接保留下來，確保不會在傳遞過程中遺失。  &lt;/li&gt;
&lt;li&gt;使用 Softmax layer 來當 Output layer  &lt;ul&gt;
&lt;li&gt;可以對 output 的數值做 normalize，直接以機率的方式呈現結果。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;Handwriting Digit Recognition  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Input =&amp;gt; Neuron Network =&amp;gt; Output  &lt;/li&gt;
&lt;li&gt;Neuron Network =&amp;gt; A function set containing the candidates  &lt;/li&gt;
&lt;li&gt;FAQ  &lt;ul&gt;
&lt;li&gt;要用幾層？每層要用多少 Neuron？  &lt;ul&gt;
&lt;li&gt;試誤 + 直覺  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;我們可以自己設計 neuron network structure 嗎？  &lt;ul&gt;
&lt;li&gt;有很多不同的結構可以選擇  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有辦法讓程式自動幫我們決定要使用哪種 structure  &lt;ul&gt;
&lt;li&gt;有，但還沒有被研究的非常透徹。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 2: goodness of function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Loss  &lt;ul&gt;
&lt;li&gt;A good function should make the loss of all examples as small as possible.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Total Loss  &lt;ul&gt;
&lt;li&gt;As small as possible  &lt;/li&gt;
&lt;li&gt;Find a function in function set that minimizes total loss  &lt;/li&gt;
&lt;li&gt;Find the network parameter &lt;code&gt;θ*&lt;/code&gt; that minimize total loss  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Step 3: pick the best function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Gradient Descent  &lt;ul&gt;
&lt;li&gt;Local minima  &lt;ul&gt;
&lt;li&gt;Very slow at the plateau  &lt;/li&gt;
&lt;li&gt;Stuck at saddle point  &lt;/li&gt;
&lt;li&gt;Stuck at local minima  &lt;/li&gt;
&lt;li&gt;Gradient descent never guarantee global minima  &lt;ul&gt;
&lt;li&gt;Use different &amp;amp; random initial point to reach different minima  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Even AlphaGo using this approach  &lt;ul&gt;
&lt;li&gt;其實 AI 並沒有那麼厲害，他們也是像探索戰爭迷霧那樣，一步一步去探索和嘗試的。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Deep Learning Toolkit&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Backpropagation  &lt;ul&gt;
&lt;li&gt;An efficient way to compute &lt;code&gt;∂L/∂w&lt;/code&gt; in neural network  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Frameworks  &lt;ul&gt;
&lt;li&gt;TensorFlow  &lt;ul&gt;
&lt;li&gt;比較多人在用且資料比較多  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Torch  &lt;/li&gt;
&lt;li&gt;Pytorch  &lt;ul&gt;
&lt;li&gt;比較多人在用且資料比較多  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Theano  &lt;ul&gt;
&lt;li&gt;AlexNet 的作者  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microsoft CNTK  &lt;/li&gt;
&lt;li&gt;Caffe  &lt;/li&gt;
&lt;li&gt;DSSTNE  &lt;/li&gt;
&lt;li&gt;mxnet  &lt;/li&gt;
&lt;li&gt;Chainer  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有 input 和 output，就可以使用這些工具幫你找尋合適的 Function Set  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Keras&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow 和 Theano 的 Wrapper  &lt;/li&gt;
&lt;li&gt;非常容易寫  &lt;/li&gt;
&lt;li&gt;雖然可以細部調整的地方沒有直接使用 TensorFlow 和 Theano 來的多，但有足夠的彈性做一些調整。  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Learning Recipe&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 Training Data 上的表現好嗎？  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不好  &lt;ul&gt;
&lt;li&gt;重新 train  &lt;/li&gt;
&lt;li&gt;可能原因  &lt;ul&gt;
&lt;li&gt;no good function exists: bad hypothesis function set =&amp;gt; reconstruct the model architecture  &lt;/li&gt;
&lt;li&gt;cannot find a good function: local optima =&amp;gt; change the training strategy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Testing Data 上的表現好嗎？  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不好的話就是 Overfitting，要重新 train model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Overfitting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;High variance  &lt;/li&gt;
&lt;li&gt;可能的解法  &lt;ul&gt;
&lt;li&gt;more training samples  &lt;/li&gt;
&lt;li&gt;dropout  &lt;ul&gt;
&lt;li&gt;每次 random 讓數個 node 不工作  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;降維  &lt;ul&gt;
&lt;li&gt;PCA  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Concluding Remarks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;3 steps of Basic Machine Learning 很重要  &lt;/li&gt;
&lt;li&gt;Stacked functions  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Part II: Variants of Neural Nets&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Convolutional Neural Network (CNN)  &lt;/li&gt;
&lt;li&gt;Recurrent Neural Network (RNN)  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Convolutional Neural Network (CNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在影像處理上被廣泛使用  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why CNN for Image?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image.  &lt;ul&gt;
&lt;li&gt;A neuron does not have to see the whole image to discover pattern.  &lt;/li&gt;
&lt;li&gt;Connecting to small region with less parameters.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions.  &lt;/li&gt;
&lt;li&gt;Subsampling the pixels will not change the object.  &lt;ul&gt;
&lt;li&gt;算是處理 image 上獨有的特性  &lt;/li&gt;
&lt;li&gt;We can subsmaple the pixel to make image smaller  &lt;ul&gt;
&lt;li&gt;Less parameters for the network to process the image  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;The Whole CNN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Image =&amp;gt; &lt;code&gt;{Convolution =&amp;gt; Max Pooling}*N&lt;/code&gt; =&amp;gt; Flatten =&amp;gt; Fully Connected Feedforward Network  &lt;/li&gt;
&lt;li&gt;特性  &lt;ul&gt;
&lt;li&gt;和 Convolution 有關  &lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image.  &lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;和 Max Pooling 有關  &lt;ul&gt;
&lt;li&gt;Subsampling the pixels will not change the object  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Image Recognition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Local Connectivity  &lt;ul&gt;
&lt;li&gt;Neurons connected to a small region  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameter Sharing  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The same feature in different positions  &lt;ul&gt;
&lt;li&gt;Neurons share the same weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Different features in the same position  &lt;ul&gt;
&lt;li&gt;Neurons have different weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convolutional Layers  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Hyper-parameters of CNN  &lt;ul&gt;
&lt;li&gt;Stride  &lt;ul&gt;
&lt;li&gt;要隔多少去算下一個 information  &lt;/li&gt;
&lt;li&gt;如果覺得這張圖上的 information 是非常鬆散的，那 stride 就可以設高一點，讓他多隔幾層再去找 pattern  &lt;/li&gt;
&lt;li&gt;如果覺得這張圖上的 information 是非常緊密的，那 stride 就只能設低一點。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Padding  &lt;ul&gt;
&lt;li&gt;讓每一層的數值不要減少的太快  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pooling Layer  &lt;ul&gt;
&lt;li&gt;Max Pooling  &lt;ul&gt;
&lt;li&gt;把最大的值保存下來  &lt;/li&gt;
&lt;li&gt;Image processing 比較常使用 Max Pooling  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Average Pooling  &lt;ul&gt;
&lt;li&gt;把平均的數值保存下來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;壓縮資訊，減少下一層需要參數的量，使其更有效率。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why Deep Learing works for image recogniton?  &lt;ul&gt;
&lt;li&gt;每個 node 會學習一些簡單的筆劃，組合起來後才會變成一個字。  &lt;/li&gt;
&lt;li&gt;愈前面的結果會愈簡單和基本，可能只是些筆劃，經過 Convolution 和 Max Pooling 後，可以用被壓縮後的較少資訊學習比較抽象的組合。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fully-Connected Layer  &lt;ul&gt;
&lt;li&gt;Global feature extraction  &lt;/li&gt;
&lt;li&gt;Softmax Layer: Classifier  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What CNN Learned  &lt;ul&gt;
&lt;li&gt;[AlexNet]  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DNN are easily fooled  &lt;ul&gt;
&lt;li&gt;可以捏造一些奇怪的 input，看起來只是一些 noise，因為 DNN 會特別著重某些 pattern，所以會將這些圖誤判為目標物。  &lt;/li&gt;
&lt;li&gt;滿多資安的論文現在在探討攻擊 DNN 的手法。  &lt;/li&gt;
&lt;li&gt;Visualizing CNN  &lt;ul&gt;
&lt;li&gt;調整 noise 的 input，使其 filter response 更接近目標物的 filter response，有點像是反過來的 training  &lt;/li&gt;
&lt;li&gt;透過 Gradient Ascent 去微調  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://deepdreamgenerator.com/"&gt;https://deepdreamgenerator.com/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Deep Style  &lt;ul&gt;
&lt;li&gt;一張圖保留 Content  &lt;/li&gt;
&lt;li&gt;另一張圖保留 Style  &lt;/li&gt;
&lt;li&gt;然後去調整保留 Content 的那張圖，並使用另一張圖的 Style  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Go Playing （下圍棋）  &lt;ul&gt;
&lt;li&gt;Conditions  &lt;ul&gt;
&lt;li&gt;Input: 目前棋盤的狀況  &lt;/li&gt;
&lt;li&gt;Output: 下一步應該下哪裡？  &lt;/li&gt;
&lt;li&gt;19x19 vector  &lt;/li&gt;
&lt;li&gt;black = 1, white = -1, none = 0  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fully-Connected Feedforward Network could be used, but why CNN?  &lt;ul&gt;
&lt;li&gt;Some patterns are much smaller than the whole image  &lt;ul&gt;
&lt;li&gt;棋譜會有一些固定的 pattern  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The same patterns appear in different regions  &lt;ul&gt;
&lt;li&gt;同樣的 pattern 有可能出現在棋盤上不同的地方  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Subsampling the pixels will not change the object  &lt;ul&gt;
&lt;li&gt;把棋譜作 subsampling 會讓整個棋譜的結果失真  &lt;/li&gt;
&lt;li&gt;因為 Subsampling 只和 Max Pooling Layer 有關，所以在 AlphaGo 的論文中有提到只有使用 Convolutional Layer，把 Max Pooling Layer 拿掉了。  &lt;/li&gt;
&lt;li&gt;如果不是很熟悉下圍棋以及 DNN 的 domain knowledge 的話，直接拿 CNN 去做是訓練不出什麼結果的，這也是為什麼 Alpha Go 會需要像黃士傑博士這樣會下圍棋又懂 Machine Learning 的人。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Recurrent Neural Network (RNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Example Application  &lt;ul&gt;
&lt;li&gt;Slot Filling  &lt;ul&gt;
&lt;li&gt;Solved by Feedforward Network?  &lt;ul&gt;
&lt;li&gt;Input: a word  &lt;/li&gt;
&lt;li&gt;Output: probability distribution that the input word belonging to the slots  &lt;/li&gt;
&lt;li&gt;Problem  &lt;ul&gt;
&lt;li&gt;Arrive Taipei on November 2nd  &lt;ul&gt;
&lt;li&gt;Taipei 是目的地  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Leave Taipei on November 2nd  &lt;ul&gt;
&lt;li&gt;Taipei 是出發地  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用 RNN 來解決  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One-Hot Vector  &lt;ul&gt;
&lt;li&gt;1-of-N Encoding  &lt;/li&gt;
&lt;li&gt;有 N 個詞就用 N 維的矩陣來表示，如果該字有出現的話值就是 1，其他值就會是 0。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RNN  &lt;ul&gt;
&lt;li&gt;The output of hidden layer are stored in the memory  &lt;/li&gt;
&lt;li&gt;Memory can be considered as another input  &lt;/li&gt;
&lt;li&gt;每一層都是拿現在看到的資訊和上一層的 memory 當成 input  &lt;/li&gt;
&lt;li&gt;不會因為層數比較多（語句比較長）就導致參數變多，參數的數量都是一樣的。  &lt;/li&gt;
&lt;li&gt;存在 memory 的 value 會影響最終的 prediction  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep RNN: 多層  &lt;/li&gt;
&lt;li&gt;Why use RNN in language processing?  &lt;ul&gt;
&lt;li&gt;因為語言是有時間順序的  &lt;/li&gt;
&lt;li&gt;如果 input 是時間順序非常重要的話，就可以考慮用 RNN 來做。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bidirectional RNN  &lt;ul&gt;
&lt;li&gt;將 input 反向來作並加入 memory  &lt;/li&gt;
&lt;li&gt;缺點是會比較費時  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning Target  &lt;ul&gt;
&lt;li&gt;會比較複雜一些  &lt;/li&gt;
&lt;li&gt;一句話有五個詞，訓練一句話等於要拿到 5 個 targets  &lt;ul&gt;
&lt;li&gt;因為要判斷每個詞的 label  &lt;/li&gt;
&lt;li&gt;因為彼此是有順序相依性的，所以 loss 會是每層 layer 相加  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training Difficulty - Rough Error Surface  &lt;ul&gt;
&lt;li&gt;The error surface is either very flat or very steep  &lt;ul&gt;
&lt;li&gt;非常難學習  &lt;/li&gt;
&lt;li&gt;所以會有一些各式各樣的小技巧出現在 RNN 裏面  &lt;ul&gt;
&lt;li&gt;Clipping  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Large &lt;code&gt;δL/δw&lt;/code&gt; =&amp;gt; Large Learning rate  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-One  &lt;ul&gt;
&lt;li&gt;Input is a vector sequence, but output is only one vector  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-Many (Output is shorter)  &lt;ul&gt;
&lt;li&gt;Both input and output are sequences, but the output is shorter  &lt;/li&gt;
&lt;li&gt;E.g. Speech Recognition  &lt;ul&gt;
&lt;li&gt;Input: vector sequence  &lt;/li&gt;
&lt;li&gt;Output: character sequence  &lt;/li&gt;
&lt;li&gt;Connectionist Temporal Classification (CTC)  &lt;ul&gt;
&lt;li&gt;加了一個額外的 symble &lt;code&gt;ϕ&lt;/code&gt; 來代表 Null  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;好好好棒棒棒棒&lt;/code&gt; vs &lt;code&gt;好ϕϕ棒ϕϕ棒&lt;/code&gt;  &lt;ul&gt;
&lt;li&gt;這樣就可以知道到底是一個棒還是兩個棒  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Many-to-Many (Output is no limitation)  &lt;ul&gt;
&lt;li&gt;Both input and output are sequences with different lengths  &lt;ul&gt;
&lt;li&gt;Sequence to sequence learning  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;E.g. Machine Translation  &lt;ul&gt;
&lt;li&gt;"Machine Learning" =&amp;gt; "機器學習"  &lt;/li&gt;
&lt;li&gt;Problem: Don't know when to stop  &lt;ul&gt;
&lt;li&gt;加上一個代表斷句或結尾的符號  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Image Caption Generation  &lt;ul&gt;
&lt;li&gt;給一張圖，描述出圖裏面有什麼  &lt;/li&gt;
&lt;li&gt;將圖餵給 CNN 後，會產出一個代表整章圖的 vector  &lt;/li&gt;
&lt;li&gt;將 vector 餵給 RNN  &lt;/li&gt;
&lt;li&gt;Example  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.captionbot.ai/"&gt;http://www.captionbot.ai/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Video Caption Generation  &lt;ul&gt;
&lt;li&gt;每一個 Video 用 CNN  &lt;/li&gt;
&lt;li&gt;Video 裡面的每一張 Image 用 RNN  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Chit-Chat Bot  &lt;ul&gt;
&lt;li&gt;拿對話中其中一方的話當 input，另一方的話當 output 去訓練。  &lt;/li&gt;
&lt;li&gt;比較常用到 &lt;a href="https://en.wikipedia.org/wiki/Long_short-term_memory"&gt;LSTM&lt;/a&gt;  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sci-Fi Short Film generated by AI - SUNSPRING  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=LY7x2lhqj"&gt;https://www.youtube.com/watch?v=LY7x2lhqj&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attention and Memory  &lt;ul&gt;
&lt;li&gt;Question =&amp;gt; Organize =&amp;gt; Answer  &lt;ul&gt;
&lt;li&gt;被稱做 Attention  &lt;/li&gt;
&lt;li&gt;只會拿有用的資訊出來回答  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attention on Sensory Info  &lt;ul&gt;
&lt;li&gt;Info from the sensors =&amp;gt; Sensory Memory == Attention ==&amp;gt; Working Memeory == Encode ==&amp;gt; Long-term Memory  &lt;/li&gt;
&lt;li&gt;Logn-term Memory == Retrieval ==&amp;gt; Working Memory  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Machine Translation with Attention  &lt;ul&gt;
&lt;li&gt;Keyword: "Attentional sequence to sequence model"  &lt;/li&gt;
&lt;li&gt;先用 match 判斷跟哪一塊的相似程度最高  &lt;/li&gt;
&lt;li&gt;目前 Google Translation 就是用這個 model 實現的  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Speech Recognition with Attention  &lt;ul&gt;
&lt;li&gt;比較深色的地方就是 Attention 比較高的部份  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Image Captioning with Attention  &lt;ul&gt;
&lt;li&gt;從錯誤的 prediction 中去瞭解判斷錯誤的可能原因  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Video Captioning with Attention  &lt;/li&gt;
&lt;li&gt;Reading Comprehension  &lt;ul&gt;
&lt;li&gt;Document =&amp;gt; 被切分成不同的詞被當作 feature  &lt;/li&gt;
&lt;li&gt;Question == RNN ==&amp;gt; q vector  &lt;/li&gt;
&lt;li&gt;根據 q vector 去決定哪一個句子最相關，再放入 DNN 裡頭去回答  &lt;/li&gt;
&lt;li&gt;Hopping  &lt;ul&gt;
&lt;li&gt;Memory Network  &lt;ul&gt;
&lt;li&gt;有可能第一次得到的結果不夠準確  &lt;/li&gt;
&lt;li&gt;用抽取出來資訊再做一次 Attention，再得到新的 information 並把它抽取出來。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When the input is a very long sequence or an image  &lt;ul&gt;
&lt;li&gt;Pay attention on partial of the input object each time  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In RNN/LSTM, larger memory implies more parameters  &lt;ul&gt;
&lt;li&gt;Increasing memory size will not increasing parameters  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Neural Turing Machine  &lt;ul&gt;
&lt;li&gt;an advanced RNN/LSTM  &lt;/li&gt;
&lt;li&gt;把 Long-term Memory 裡頭的資訊 retrieve 出來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Part III: Beyond Supervised Learning &amp;amp; Recent Trends (Unsupervised Learning)&lt;/h1&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Big data != Big annotated data  &lt;ul&gt;
&lt;li&gt;What can we do if there is no sufficient labelled training data?  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Machine learning techniques include:  &lt;ul&gt;
&lt;li&gt;Supervised learning (if we have labelled data)  &lt;/li&gt;
&lt;li&gt;Reinforcement learning (if we have an environment for reward)  &lt;/li&gt;
&lt;li&gt;Unsupervised learning (if we do not have labelled data)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Semi-Supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;應用環境  &lt;ul&gt;
&lt;li&gt;沒有全部的 input data 都有 label 時  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;The distribution of the unlabeled data provides some cues  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Transfer Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;應用環境  &lt;ul&gt;
&lt;li&gt;Input data 中沒有 output 想要的 class label  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Using sufficient labeled data to learn a CNN  &lt;/li&gt;
&lt;li&gt;Using this CNN as feature extractor  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;舉例  &lt;ul&gt;
&lt;li&gt;研究生 vs 漫畫家  &lt;ul&gt;
&lt;li&gt;研究生 == 漫畫家  &lt;/li&gt;
&lt;li&gt;指導教授 == 責任編輯  &lt;/li&gt;
&lt;li&gt;跑實驗 == 畫分鏡  &lt;/li&gt;
&lt;li&gt;投稿期刊 == 投稿 Jump  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Unsupervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Representation Learning: 化繁為簡  &lt;/li&gt;
&lt;li&gt;Generative Model: 無中生有  &lt;/li&gt;
&lt;li&gt;化繁為簡和無中生有的過程是相反的  &lt;ul&gt;
&lt;li&gt;化繁為簡：拿到很多跟樹有關的圖片，簡化得出一個代表樹的 output，學習到的是這些圖片共同的特徵  &lt;/li&gt;
&lt;li&gt;無中生有：code 經過 function 之後就生成很多跟樹很像的圖片  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Latent Factors  &lt;ul&gt;
&lt;li&gt;共同特徵  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;化繁為簡 Representation Learning  &lt;ul&gt;
&lt;li&gt;Autoencoder  &lt;ul&gt;
&lt;li&gt;希望能把比較重要的資訊壓縮到比較小的 pattern 裏面  &lt;/li&gt;
&lt;li&gt;represent the images of digits in a more compact way  &lt;/li&gt;
&lt;li&gt;Output of the hidden layer is the code  &lt;/li&gt;
&lt;li&gt;Deep autoencoder  &lt;/li&gt;
&lt;li&gt;Similar Image Retrieval  &lt;/li&gt;
&lt;li&gt;可以把 image 最重要的 feature 保留起來  &lt;/li&gt;
&lt;li&gt;For DNN Pre-Training  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word Vector/Embedding  &lt;ul&gt;
&lt;li&gt;Machine learn the meaning of words from reading a lot of documents without supervision  &lt;/li&gt;
&lt;li&gt;A word can be understood by its context  &lt;/li&gt;
&lt;li&gt;類似的句型中，同樣位置的不相同詞可能有高度相關性  &lt;/li&gt;
&lt;li&gt;Prediction-Based  &lt;ul&gt;
&lt;li&gt;給前面的字 predict 下一個字 (Linear Model)  &lt;ul&gt;
&lt;li&gt;前面的字當 input，後面的字當 output，一直這樣接下去。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Various Architecture  &lt;ul&gt;
&lt;li&gt;Continuous bag of word (CBOW) model  &lt;ul&gt;
&lt;li&gt;給兩邊的字 predict 中間的字  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Skip-gram  &lt;ul&gt;
&lt;li&gt;給中間的字 predict 兩邊的字  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;完全不需要 label data，程式可以自己去學習這些詞之間的關係  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;無中生有 Generative model  &lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;想讓程式自動幫我們生不同的 training data  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.openai.com/generative-models/"&gt;https://blog.openai.com/generative-models/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PixelRNN  &lt;ul&gt;
&lt;li&gt;To create an image, generating a pixel each time  &lt;/li&gt;
&lt;li&gt;Can be trained just with a large collection of images without any annotation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generative Adversarial Network (GAN)  &lt;ul&gt;
&lt;li&gt;Discriminative vs Generative Models  &lt;ul&gt;
&lt;li&gt;Discriminative  &lt;ul&gt;
&lt;li&gt;learns a function that maps the input data (x) to some desired output class label (y)  &lt;ul&gt;
&lt;li&gt;directly learn the conditional distribution P(y|x)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generative  &lt;ul&gt;
&lt;li&gt;tries to learn the joint probability of the input data and labels simultaneously, i.e. P(x,y)  &lt;ul&gt;
&lt;li&gt;can be converted to P(y|x) for classification via Bayes rule  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;generative models have the potential to understand and explain&lt;br /&gt;
the underlying structure of the input data even when there are no labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;跟演化的感覺有點類似  &lt;ul&gt;
&lt;li&gt;Generator  &lt;ul&gt;
&lt;li&gt;Hidden Layer (code) ===decode===&amp;gt; output layer =&amp;gt; output  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Two competing neural networks: generator &amp;amp; discriminator  &lt;/li&gt;
&lt;li&gt;noise ==generator==&amp;gt; generator sample =&amp;gt; discriminator ==yes/no==&amp;gt; data sample  &lt;/li&gt;
&lt;li&gt;generator 生出圖片，discriminator 判斷這張產生出來的圖片是不是真的  &lt;/li&gt;
&lt;li&gt;彼此之間會互相競爭學習  &lt;/li&gt;
&lt;li&gt;Training two networks jointly =&amp;gt; the generator knows how to adapt its parameters in order to produce output data that can fool the discriminator  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Examples  &lt;ul&gt;
&lt;li&gt;&lt;a href="https://openai.com/blog/generative-models"&gt;Cifar-10&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Generated Bedrooms  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mattya/chainer-DCGAN"&gt;Comics Drawing&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Pokémon Creation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;概念  &lt;ul&gt;
&lt;li&gt;Agent, Environment 之間彼此是可以互動的  &lt;/li&gt;
&lt;li&gt;Environment 會給 Agent 一個 Observation  &lt;/li&gt;
&lt;li&gt;Agent 會對這個 Observation 做出 Action  &lt;/li&gt;
&lt;li&gt;Environment 會根據 Action 的不同給予 Agent 不同的 Reward  &lt;/li&gt;
&lt;li&gt;根據 Reward 來學習要做或不做哪些行為  &lt;/li&gt;
&lt;li&gt;Agent learns to take actions to maximize expected reward.  &lt;/li&gt;
&lt;li&gt;困難點  &lt;ul&gt;
&lt;li&gt;可能的 sequence 是非常龐大的  &lt;/li&gt;
&lt;li&gt;很難調整，因為只拿得到一連串的 Actions 之後的 Reward，無法確定到底是錯在哪一個 Action  &lt;/li&gt;
&lt;li&gt;Reward may be delayed  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supervised vs Reinforcement  &lt;ul&gt;
&lt;li&gt;Supervised  &lt;ul&gt;
&lt;li&gt;就像在學校裏面，每一步都有老師會帶領你，告訴你每一步是對是錯  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement  &lt;ul&gt;
&lt;li&gt;做了一連串的動作以後，到一個正面或負面的回饋，不確定到底問題出錯在哪一個地方。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;範例  &lt;ul&gt;
&lt;li&gt;走迷宮  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning Approach  &lt;ul&gt;
&lt;li&gt;Policy-based RL  &lt;ul&gt;
&lt;li&gt;Search directly for optimal policy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Value-based RL  &lt;ul&gt;
&lt;li&gt;Estimate the optimal value function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model-based RL  &lt;ul&gt;
&lt;li&gt;Build a model of the environment  &lt;/li&gt;
&lt;li&gt;Plan (e.g. by lookahead) using model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning  &lt;ul&gt;
&lt;li&gt;Idea: deep learning for reinforcement learning  &lt;ul&gt;
&lt;li&gt;Use deep neural networks to represent  &lt;/li&gt;
&lt;li&gt;Optimize loss function by SGD  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Value Function Approximation  &lt;/li&gt;
&lt;li&gt;Q-Networks  &lt;ul&gt;
&lt;li&gt;Q-networks represent value functions with weights  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Q-Learning  &lt;ul&gt;
&lt;li&gt;Goal: estimate optimal Q-values  &lt;ul&gt;
&lt;li&gt;Optimal Q-values obey a Bellman equation  &lt;/li&gt;
&lt;li&gt;Value iteration algorithms solve the Bellman equation  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Q-Networks (DQN)  &lt;/li&gt;
&lt;li&gt;Stability Issues with Deep RL  &lt;ul&gt;
&lt;li&gt;Naive Q-learning oscillates or diverges with neural nets  &lt;ul&gt;
&lt;li&gt;Data is sequential  &lt;ul&gt;
&lt;li&gt;Successive samples are correlated, non-iid (independent and&lt;br /&gt;
identically distributed)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Policy changes rapidly with slight changes to Q-values  &lt;ul&gt;
&lt;li&gt;Policy may oscillate  &lt;/li&gt;
&lt;li&gt;Distribution of data can swing from one extreme to another  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scale of rewards and Q-values is unknown  &lt;ul&gt;
&lt;li&gt;Naive Q-learning gradients can be unstable when backpropagated  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stable Solutions for DQN  &lt;ul&gt;
&lt;li&gt;DQN provides a stable solutions to deep value-based RL  &lt;ul&gt;
&lt;li&gt;Use experience replay  &lt;ul&gt;
&lt;li&gt;Break correlations in data, bring us back to iid setting  &lt;/li&gt;
&lt;li&gt;Learn from all past policies  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Freeze target Q-network  &lt;ul&gt;
&lt;li&gt;Avoid oscillation  &lt;/li&gt;
&lt;li&gt;Break correlations between Q-network and target  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clip rewards or normalize network adaptively to sensible range  &lt;ul&gt;
&lt;li&gt;Robust gradients  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DQN in Atari  &lt;ul&gt;
&lt;li&gt;Goal: end-to-end learning of values Q(s, a) from pixels  &lt;ul&gt;
&lt;li&gt;Input: state is stack of raw pixels from last 4 frames  &lt;/li&gt;
&lt;li&gt;Output: Q(s, a) for all joystick/button positions a  &lt;/li&gt;
&lt;li&gt;Reward is the score change for that step  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DQN in E2E Task-Completion Bot  &lt;ul&gt;
&lt;li&gt;Simulated User  &lt;ul&gt;
&lt;li&gt;Generate interactions based on a predefined fake goal  &lt;/li&gt;
&lt;li&gt;Automatically learn strategy by training on the simulated data  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model-Based Deep RL  &lt;ul&gt;
&lt;li&gt;Goal: learn a transition model of the environment and plan based on the transition model  &lt;/li&gt;
&lt;li&gt;Model-based deep RL is challenging, and so far has failed in Atari  &lt;/li&gt;
&lt;li&gt;Model-Based Deep RL in AlphaGo  &lt;ul&gt;
&lt;li&gt;Monte-Carlo tree search (MCTS)  &lt;ul&gt;
&lt;li&gt;MCTS simulates future trajectories  &lt;/li&gt;
&lt;li&gt;Builds large lookahead search tree with millions of positions  &lt;/li&gt;
&lt;li&gt;State-of-the-art Go programs use MCTS  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolutional Networks  &lt;ul&gt;
&lt;li&gt;12-layer CNN trained to predict expert moves  &lt;/li&gt;
&lt;li&gt;Raw CNN (looking at 1 position, no search at all) equals performance of MoGo with 105 position search tree  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;More Applications  &lt;ul&gt;
&lt;li&gt;AlphaGo  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0JL04JJjocc"&gt;Flying Helicoptor&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0xo1Ldx3L5Q"&gt;Driving&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bloomberg.com/news/articles/2016-07-19/google-cuts-its-giant-electricity-bill-with-deepmind-powered-ai"&gt;Google Cuts Its Giant Electricity Bill With DeepMind-Powered AI&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://universe.openai.com/"&gt;OpenAI Universe&lt;/a&gt;  &lt;ul&gt;
&lt;li&gt;Software platform for measuring and training an AI's general&lt;br /&gt;
intelligence via the &lt;a href="https://gym.openai.com/"&gt;OpenAI gym&lt;/a&gt; environment  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning &amp;amp; Deep Learning 需要  &lt;ul&gt;
&lt;li&gt;足夠的運算資源  &lt;/li&gt;
&lt;li&gt;各種經驗及技巧  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;FAQ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep Learning 的 model 會是 non-linear 的  &lt;/li&gt;
&lt;li&gt;機器翻譯目前在台灣的狀況如何？要如何著手？  &lt;ul&gt;
&lt;li&gt;機器翻譯的話，目前在國外算是滿成熟的，目前會使用 RNN 來做。  &lt;/li&gt;
&lt;li&gt;如果是台語的部份，目前好像比較少看到，會是個還有發展空間的方向。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;為什麼需要 Activation Function？他在 Deep Learning 中扮演的角色是什麼？  &lt;ul&gt;
&lt;li&gt;處理 non-linear 的部份，如果沒有 Actication Function 的話，多層的結果用一層就可以去表示。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;為什麼會選擇 Sigmoid 作為 Activation Function?  &lt;ul&gt;
&lt;li&gt;其實有很多種 Activation Function，拿 Sigmoid 來講是因為他比較簡單，把 output 壓在 -1~1 之間  &lt;/li&gt;
&lt;li&gt;另外一個比較常見的是 Relu 這個 Activation Function  &lt;ul&gt;
&lt;li&gt;0 以下的就刪除掉  &lt;/li&gt;
&lt;li&gt;避免 information 被壓縮的太小，用來解決經過太多層之後 information 被壓得太小。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep Learning 的最佳化要具備哪些能力  &lt;ul&gt;
&lt;li&gt;如果是純理論的部份會跟數學方面相關。  &lt;/li&gt;
&lt;li&gt;但如果是實務上的 task，會跟該 task 的 domain knowledge 比較相關。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CNN 對於影像旋轉是否也有夠好的識別度？  &lt;ul&gt;
&lt;li&gt;第一個作法就是把你的 training data 也旋轉過再丟進去訓練  &lt;/li&gt;
&lt;li&gt;另外一個作法是使用會考慮旋轉相關的 model 放進去 train，input data 不需要特別旋轉過  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;學 Machine Learning 需要學習微積分、統計和線性代數嗎？  &lt;ul&gt;
&lt;li&gt;基本的微積分概念是要的，但沒有很複雜，如果完全不會微分的話要學一下。  &lt;/li&gt;
&lt;li&gt;統計的話基本概念要有，但不會太多。&lt;br /&gt;
 線性代數是最重要的，會看到很多 vector, matrix 以及 space 上的處理，有很多假設是必須要知道的。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Deep Learning"></category><category term="DNN"></category><category term="CNN"></category><category term="RNN"></category><category term="Machine Learning"></category></entry></feed>