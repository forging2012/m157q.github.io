<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Just for noting</title><link href="https://blog.m157q.tw/" rel="alternate"></link><link href="https://blog.m157q.tw/feeds/tag.keras.atom.xml" rel="self"></link><id>https://blog.m157q.tw/</id><updated>2017-08-13T17:08:45+08:00</updated><entry><title>台灣資料科學年會之系列活動：手把手的深度學習實務</title><link href="https://blog.m157q.tw/posts/2017/08/13/deep-learning-hands-on-step-by-step-datasci-tw/" rel="alternate"></link><published>2017-08-13T17:08:45+08:00</published><updated>2017-08-13T17:08:45+08:00</updated><author><name>m157q</name></author><id>tag:blog.m157q.tw,2017-08-13:posts/2017/08/13/deep-learning-hands-on-step-by-step-datasci-tw/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://foundation.datasci.tw/step-by-step-dl-170813/"&gt;http://foundation.datasci.tw/step-by-step-dl-170813/&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://drive.google.com/file/d/0B9cCeTKOkfWIbWtjdWJaRl9YRmM/view?usp=sharing"&gt;Slides&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;六步完模 – 建立深度學習模型&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;決定 hidden layers 層數與其中的 neurons 數量  &lt;/li&gt;
&lt;li&gt;決定該層使用的 activation function  &lt;/li&gt;
&lt;li&gt;決定模型的 loss function  &lt;/li&gt;
&lt;li&gt;決定 optimizer  &lt;ul&gt;
&lt;li&gt;Parameters: learning rate, momentum, decay  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;編譯模型 (Compile model)  &lt;/li&gt;
&lt;li&gt;開始訓練囉!(Fit model)  &lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h3&gt;關於 &lt;code&gt;validation_split&lt;/code&gt; 要注意的小地方&lt;/h3&gt;
&lt;p&gt;用 Keras 的 &lt;code&gt;validation_split&lt;/code&gt; 之前要記得把資料先弄亂，&lt;br /&gt;
因為它會從資料的最尾端開始取，&lt;br /&gt;
如果沒有弄亂的話切出來的資料 bias 會很大。&lt;br /&gt;
可以使用 &lt;code&gt;np.shuffle&lt;/code&gt; 來弄亂  &lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Functional API&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Why “Functional API” ?  &lt;ul&gt;
&lt;li&gt;All layers and models are callable (like function call)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;  
&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;  
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;+ 類似 f(x) 的寫法  
    + Dense(10) == f  
    + input == x  
+ 好處是可以 assign 給自己後再用 for loop 很快建非常多層 layer，不用一直用 `model.add`  
+ Easy to manipulate various inpout sources
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x1 = input(shape=(10,))  
y1 = Dense(100)(x1)  

x2 = input(shape=(20,))  
new_x2 = keras.layers.concatenate([y1,x2])  
output = Dense(200)(new_x2)  

Model = Model(inputs=[x1,x2],outputs=[output])  
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;Loss function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;為什麼 Cross-entropy 比 Squared error 好？  &lt;ul&gt;
&lt;li&gt;Cross-entropy 的 Gradient 比較大，學習速度比較快。  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.complex-systems.com/pdf/02-6-1.pdf"&gt;The error surface of logarithmic functions is steeper than&lt;br /&gt;
that of quadratic functions.&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How to select Loss function  &lt;ul&gt;
&lt;li&gt;Classification 常用 cross-entropy  &lt;ul&gt;
&lt;li&gt;搭配 softmax 當作 output layer 的 activation function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Regression 常用 mean absolute/squared error  &lt;/li&gt;
&lt;li&gt;對特定問題定義 loss function  &lt;ul&gt;
&lt;li&gt;Unbalanced dataset, class 0 : class 1 = 99 : 1  &lt;ul&gt;
&lt;li&gt;Class 1 做錯的話，給它 penalty 99  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-defined loss function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Learning Rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;觀察 Loss，如果有振盪的話，代表 learning rate 可能太大  &lt;/li&gt;
&lt;li&gt;觀察 Loss，下降的太緩慢的話，代表 learning rate 可能太小  &lt;/li&gt;
&lt;li&gt;選擇適合的 learning rate 對於 training model 會是很大的影響  &lt;/li&gt;
&lt;li&gt;通常不會大於 0.1  &lt;/li&gt;
&lt;li&gt;一次調整一個數量級  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Activation Function&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Activation Function 可能是最重要的  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Sigmoid 介於 0~1 之間  &lt;/li&gt;
&lt;li&gt;Tanh, Softsign 介於 -1~1 之間  &lt;/li&gt;
&lt;li&gt;值域是有限制的  &lt;ul&gt;
&lt;li&gt;Input 過大或過小影響其實不大  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Derivatives of Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Input 過大或過小時，Gradient 太小，學習就會很慢  &lt;/li&gt;
&lt;li&gt;所以通常太深的 model 不建議用這 3 個 Activation Function  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Drawbacks of Sigmoid, Tanh, Softsign  &lt;ul&gt;
&lt;li&gt;Vanishing gradient problem  &lt;ul&gt;
&lt;li&gt;原因: input 被壓縮到一個相對很小的output range  &lt;/li&gt;
&lt;li&gt;結果: 很大的 input 變化只能產生很小的 output 變化 =&amp;gt; Gradient 小 =&amp;gt; 無法有效地學習  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特別不適用於深的深度學習模型  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ReLU, Softplus  &lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;在 TensorFlow 上用 Softplus 好像會遇到一些問題  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Derivatives of ReLU, Softplus  &lt;ul&gt;
&lt;li&gt;ReLU 在輸入小於零時, gradient 等於零,會有問題嗎?  &lt;ul&gt;
&lt;li&gt;小於 0 的時候可能就不學習了，所以有人提出了 Leaky ReLU  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Leaky ReLU  &lt;ul&gt;
&lt;li&gt;Allow a small gradient while the input to activation function smaller than 0  &lt;/li&gt;
&lt;li&gt;在 input &amp;lt; 0 時，還是給他一點些微的斜率  &lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;在用 ReLU 的時候 Learning rate 可能要用小一點，效果會比較好。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Optimizer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SGD – Stochastic Gradient Descent  &lt;ul&gt;
&lt;li&gt;Stochastic gradient descent  &lt;/li&gt;
&lt;li&gt;支援 momentum, learning rate decay, Nesterov momentum  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizer.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Momentum 的影響  &lt;ul&gt;
&lt;li&gt;無 momentum: &lt;code&gt;update = -lr*gradient&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;有 momentum: &lt;code&gt;update = -lr*gradient + m*last_update&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning rate decay after update once  &lt;ul&gt;
&lt;li&gt;屬於 &lt;code&gt;1/t decay =&amp;gt; lr = lr / (1 + decay*t)&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;t: number of done updates  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Momentum vs Nesterov Momentum  &lt;ul&gt;
&lt;li&gt;Momentum  &lt;ul&gt;
&lt;li&gt;先算 gradient  &lt;/li&gt;
&lt;li&gt;加上 momentum  &lt;/li&gt;
&lt;li&gt;更新  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nesterov Momentum  &lt;ul&gt;
&lt;li&gt;加上 momentum  &lt;/li&gt;
&lt;li&gt;再算 gradient  &lt;/li&gt;
&lt;li&gt;更新  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;兩者出來的效果沒有太大的差別，沒有誰比較好，只是聽到有人用 Nesterov 的時候要知道差別。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adagrad – Adaptive Learning Rate  &lt;ul&gt;
&lt;li&gt;因材施教:每個參數都有不同的 learning rate  &lt;/li&gt;
&lt;li&gt;根據之前所有 gradient 的 root mean square 修改  &lt;/li&gt;
&lt;li&gt;Feature scales 不同,需要不同的 learning rates  &lt;/li&gt;
&lt;li&gt;每個 weight 收斂的速度不一致  &lt;ul&gt;
&lt;li&gt;但 learning rate 沒有隨著減少的話  bumpy  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;根據之前所有 gradient 的 root mean square 修改  &lt;/li&gt;
&lt;li&gt;老馬識途,參考之前的經驗修正現在的步伐  &lt;/li&gt;
&lt;li&gt;不完全相信當下的 gradient  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RMSprop – Similar with Adagrad  &lt;ul&gt;
&lt;li&gt;另一種參考過去 gradient 的方式  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adagrad 不管多久之前的經驗都把其權重視為相同的，RMSprop 就是針對這部份做改進，愈久之前的經驗其權重會變得愈低。  &lt;/li&gt;
&lt;li&gt;這個 Activation 是作者在 Coursera 授課時提出的，沒有論文，所以大家在論文使用這個 activation function 的時候都會 cite 那個 coursera 課程的網址，而且還不少人用的 XDDD  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adam – Similar with RMSprop + Momentum  &lt;ul&gt;
&lt;li&gt;Close to RMSprop + Momentum  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1412.6980v8.pdf"&gt;ADAM: A Method For Stochastic Optimization&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;In practice, 不改參數也會做得很好  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;keras.optimizer.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nadam – Adam + Nesterov Momentum  &lt;/li&gt;
&lt;li&gt;How to select Optimizer  &lt;ul&gt;
&lt;li&gt;一般的起手式: Adam  &lt;ul&gt;
&lt;li&gt;Adaptive learning rate for every weights  &lt;/li&gt;
&lt;li&gt;Momentum included  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Keras 推薦 RNN 使用 RMSProp  &lt;ul&gt;
&lt;li&gt;在訓練 RNN 需要注意 explosive gradient 的問題 =&amp;gt; clip gradient 的暴力美學  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RMSProp 與 Adam 的戰爭仍在延燒  &lt;ul&gt;
&lt;li&gt;各有千秋  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;處理 Overfitting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Regularization  &lt;ul&gt;
&lt;li&gt;限制 weights 的大小讓 output 曲線比較平滑  &lt;/li&gt;
&lt;li&gt;Weight 較小，input 的差異對 output 產生的影響比較沒有那麼大  &lt;/li&gt;
&lt;li&gt;α (Regularizer) 是用來調整 regularization 的比重  &lt;ul&gt;
&lt;li&gt;避免顧此失彼 (降低 weights 的大小而犧牲模型準確性)&lt;br /&gt;
避免顧此失彼 (降低 weights 的大小而犧牲模型準確性)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;L1 and L2 Regularizers  &lt;ul&gt;
&lt;li&gt;L1 norm: Sum of absolute values  &lt;/li&gt;
&lt;li&gt;L2 norm: Root mean square of absolute values  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Early Stopping  &lt;ul&gt;
&lt;li&gt;希望在 Model overfitting 之前就停止 training  &lt;/li&gt;
&lt;li&gt;假如可以停在 loss 最低的點的話就好了  &lt;/li&gt;
&lt;li&gt;Early Stopping in Keras  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;from keras.callbacks import EarlyStopping&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;early_stopping=EarlyStopping(monitor='val_loss', patience=3)&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;monitor: 要監控的 performance index  &lt;/li&gt;
&lt;li&gt;patience: 可以容忍連續幾次的不思長進  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dropout  &lt;ul&gt;
&lt;li&gt;What is Dropout  &lt;ul&gt;
&lt;li&gt;原本為 neurons 跟 neurons 之間為 fully connected  &lt;/li&gt;
&lt;li&gt;在訓練過程中,隨機拿掉一些連結 (weight 設為0)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;會造成 training performance 變差  &lt;ul&gt;
&lt;li&gt;Error 變大 =&amp;gt; 每個 neuron 修正得越多 =&amp;gt; 做得越好  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Implications  &lt;ul&gt;
&lt;li&gt;增加訓練的難度，在真正的考驗時爆發  &lt;/li&gt;
&lt;li&gt;Dropout 可視為一種終極的 ensemble 方法，N 個 weights 會有 2^N 種 network structures  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通常只加在 hidden layer，不會加在 output layer，因為影響太大了，除非 output layer 的 dimension 很大。  &lt;/li&gt;
&lt;li&gt;注意事項  &lt;ul&gt;
&lt;li&gt;「不要一開始就加入 Dropout」*3  &lt;/li&gt;
&lt;li&gt;確定有遇到 Overfitting 再加 Dropout  &lt;/li&gt;
&lt;li&gt;Dropout 會讓 training performance 變差  &lt;/li&gt;
&lt;li&gt;確定 performance 夠好再加 Dropout，不然 Performance 變低，就算解掉了 Overfitting，出來的結果也沒啥用。  &lt;/li&gt;
&lt;li&gt;Dropout 是在避免 overfitting，不是萬靈丹  &lt;/li&gt;
&lt;li&gt;參數少時，regularization  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Callbacks: 善用 Callbacks 幫助你躺著 train models&lt;/h3&gt;
&lt;h4&gt;Callback Class&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Callbacks&lt;/span&gt;  

&lt;span class="n"&gt;Class&lt;/span&gt; &lt;span class="n"&gt;LossHistory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Callbacks&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_train_begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;  

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_batch_end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;acc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;val_acc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  

    &lt;span class="n"&gt;loss_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LossHistory&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Callback 的時機&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;on_train_begin  &lt;/li&gt;
&lt;li&gt;on_train_end  &lt;/li&gt;
&lt;li&gt;on_batch_begin  &lt;/li&gt;
&lt;li&gt;on_batch_end  &lt;/li&gt;
&lt;li&gt;on_epoch_begin  &lt;/li&gt;
&lt;li&gt;on_epoch_end  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;LearningRateScheduler&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LearningRateScheduler&lt;/span&gt;  

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;step_decay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  
    &lt;span class="n"&gt;initial_lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;  
    &lt;span class="n"&gt;lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initial_lrate&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.999&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lrate&lt;/span&gt;  

&lt;span class="n"&gt;Lrate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LearningRateScheduler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_decay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;ModelCheckpoint&lt;/h4&gt;
&lt;p&gt;超級好用  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.callbacks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ModelCheckpoint&lt;/span&gt;  

&lt;span class="n"&gt;checkpoint&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ModelCheckpoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;  
    &lt;span class="s1"&gt;&amp;#39;model.h5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;monitor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;verbose&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;save_best_only&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
    &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;min&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  
&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mode&lt;/code&gt; 可以設定成 &lt;code&gt;'auto'&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;在 &lt;code&gt;model.fit&lt;/code&gt; 時加入 Callbacks&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;history = model.fit(  
    X_train,  
    Y_train,  
    batch_size=16,  
    verbose=0,  
    epochs=30,  
    shuffle=True,  
    validation_split=0.1,  
    callbacks=[  
        early_stopping,  
        loss_history,  
        lrate,  
        checkpoint,  
    ],  
)  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;但也不要一開始就加一堆 callbacks&lt;br /&gt;
尤其是 Learning Rate Scheduler&lt;br /&gt;
不好的 Learning Rate Scheduler 會導致不好的結果  &lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Semi-supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;解決的問題  &lt;ul&gt;
&lt;li&gt;收集到的標籤遠少於實際擁有的資料量  &lt;ul&gt;
&lt;li&gt;該如何增加 label 呢?  &lt;ul&gt;
&lt;li&gt;Crowd-sourcing  &lt;/li&gt;
&lt;li&gt;Semi-supervised learning  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;步驟  &lt;ul&gt;
&lt;li&gt;先用 labeled dataset to train model  &lt;ul&gt;
&lt;li&gt;至少 train 到一定的程度 (良心事業)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;拿 unlabeled dataset 來測試，挑出預測好的 unlabeled dataset  &lt;/li&gt;
&lt;li&gt;假設預測的都是對的 (unlabeled =&amp;gt; labeled)  &lt;ul&gt;
&lt;li&gt;有更多 labeled dataset 了!  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Repeat the above steps  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意事項  &lt;ul&gt;
&lt;li&gt;加入品質不佳的 labels 反而會讓 model 變差  &lt;/li&gt;
&lt;li&gt;要注意加入的資料有沒有偏差的情況，否則最後 train 出來的 model 會變成只偏向某一類的結果  &lt;/li&gt;
&lt;li&gt;慎選要加入的 samples  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Transfer Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;“transfer”: use the knowledge learned from task A to tackle another task B  &lt;/li&gt;
&lt;li&gt;Use as Fixed Feature Extractor  &lt;ul&gt;
&lt;li&gt;A known model, like VGG, trained on ImageNet  &lt;/li&gt;
&lt;li&gt;ImageNet: 10 millions images with labels  &lt;/li&gt;
&lt;li&gt;取某一個 layer output 當作 feature vectors  &lt;/li&gt;
&lt;li&gt;Train a classifier based on the features extracted by a known model  &lt;/li&gt;
&lt;li&gt;當資料很少的時候這招很好用  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use as Initialization  &lt;ul&gt;
&lt;li&gt;Initialize your net by the weights of a known model  &lt;/li&gt;
&lt;li&gt;Use your dataset to further train your model  &lt;/li&gt;
&lt;li&gt;Fine-tuning the known model  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Short Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Unlabeled data (lack of y) =&amp;gt; Semi-supervised learning  &lt;/li&gt;
&lt;li&gt;Insufficient data (lack of both x and y) =&amp;gt; Transfer learning (focus on layer transfer)  &lt;ul&gt;
&lt;li&gt;Use as fixed feature extractor  &lt;/li&gt;
&lt;li&gt;Use as initialization  &lt;/li&gt;
&lt;li&gt;Resources: https://keras.io/applications/  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h2&gt;Convolutional Neural Network (CNN)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;只要 input 是二維以上，且要找特定的 Pattern 的話，就可以用 CNN，不侷限於影像。  &lt;/li&gt;
&lt;li&gt;DNN 的輸入是一維的向量,那二維的矩陣呢? 例如：圖形資料  &lt;/li&gt;
&lt;li&gt;將圖形轉換成一維向量  &lt;ul&gt;
&lt;li&gt;Weight 數過多,造成 training 所需時間太長  &lt;/li&gt;
&lt;li&gt;左上的圖形跟右下的圖形真的有關係嗎?  &lt;ul&gt;
&lt;li&gt;只要留下重要的地方就好了，不需要全部的 neuron 都連接起來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;圖的構成  &lt;ul&gt;
&lt;li&gt;線條 (Line Segment)  &lt;/li&gt;
&lt;li&gt;圖案 (Pattern)  &lt;/li&gt;
&lt;li&gt;物件 (Object)  &lt;/li&gt;
&lt;li&gt;場景 (Scene)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;辨識一個物件只需要幾個特定的圖案  &lt;/li&gt;
&lt;li&gt;Property  &lt;ul&gt;
&lt;li&gt;What: 圖案的類型  &lt;/li&gt;
&lt;li&gt;Where: 重複的圖案可能出現在很多不同的地方  &lt;/li&gt;
&lt;li&gt;Size: 大小的變化並沒有太多的影響  &lt;ul&gt;
&lt;li&gt;Subsampling  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolution in Computer Vision  &lt;ul&gt;
&lt;li&gt;Common applications  &lt;ul&gt;
&lt;li&gt;模糊化、銳利化、浮雕  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://setosa.io/ev/image-kernels/"&gt;http://setosa.io/ev/image-kernels/&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adding each pixel and its local neighbors which are weighted by a filter (kernel)  &lt;/li&gt;
&lt;li&gt;Perform this convolution process to every pixels  &lt;ul&gt;
&lt;li&gt;當 pixel 的 value 高的時候，代表 pattern 有出現在該位置  &lt;/li&gt;
&lt;li&gt;當 pixel 的 value 低的時候，代表 pattern 沒有出現在該位置  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A filter could be seen as a pattern  &lt;/li&gt;
&lt;li&gt;常拿來做 Edge Detection  &lt;ul&gt;
&lt;li&gt;edge = 亮度變化大的地方  &lt;/li&gt;
&lt;li&gt;凸顯兩像素之間的差異  &lt;/li&gt;
&lt;li&gt;如果覺得 gap 太小的話，可以再乘上一個 constant 將其凸顯出來  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相鄰兩像素值差異越大,convolution 後新像素絕對值越大  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolutional Layer  &lt;ul&gt;
&lt;li&gt;Convolution 執行越多次影像越小  &lt;/li&gt;
&lt;li&gt;Hyper-parameters of Convolutional Layer  &lt;ul&gt;
&lt;li&gt;Filter size  &lt;/li&gt;
&lt;li&gt;Zero-padding  &lt;ul&gt;
&lt;li&gt;Add additional zeros at the border of image  &lt;/li&gt;
&lt;li&gt;Zero-padding 不會影響 convolution 的性質  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stride  &lt;ul&gt;
&lt;li&gt;Shrink the output of the convolutional layer  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Depth (total number of filters)  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pooling Layer  &lt;ul&gt;
&lt;li&gt;Why do we need pooling layers?  &lt;ul&gt;
&lt;li&gt;Reduce the number of weights  &lt;/li&gt;
&lt;li&gt;Prevent overfitting  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Max pooling  &lt;ul&gt;
&lt;li&gt;Consider the existence of patterns in each region  &lt;/li&gt;
&lt;li&gt;在作 Classification 上用得到  &lt;ul&gt;
&lt;li&gt;因為我們在做分類的時候會找尋特定的 pattern 是否有出現在該圖片中  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;但是會有些資訊喪失  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Average Pooling  &lt;ul&gt;
&lt;li&gt;因為是取平均的關係，所以出來的結果很高的話，代表該區域的值都很高，所以 pattern 出現在該位置的可能性也很高  &lt;/li&gt;
&lt;li&gt;用來找尋一再重複出現的 pattern  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A CNN Example (Object Recognition)  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/convolutional-networks/"&gt;CS321n, Standford&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Filters Visualization  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.rsipvision.com/exploring-deep-learning/"&gt;RSIP VISION&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;CNN in Keras&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Concatenate Datasets by Numpy Functions  &lt;ul&gt;
&lt;li&gt;hstack, dim(6,)  &lt;ul&gt;
&lt;li&gt;[1, 2, 3, 4, 5, 6], Labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vstack, dim(2,3)  &lt;ul&gt;
&lt;li&gt;[[1, 2, 3], [4, 5, 6]], Pixel values  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;dstack, dim(1, 3, 2)  &lt;ul&gt;
&lt;li&gt;[[1, 2], [3, 4], [5, 6]], Dimensions  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Concatenating Input Datasets  &lt;ul&gt;
&lt;li&gt;利用 vstack 連接 pixel values;用 hstack 連接 labels  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reshape the Training/Testing Inputs  &lt;ul&gt;
&lt;li&gt;利用影像的長寬資訊先將 RGB 影像分開,再利用 reshape 函式將一維向量轉換為二維矩陣,最後用 dstack 將 RGB image 連接成三維陣列  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Saving Each Data as Image  &lt;ul&gt;
&lt;li&gt;&lt;code&gt;scipy.misc.imsave&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;PIL.Image&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building Your Own CNN Model  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;#39;&amp;#39;&amp;#39;CNN model&amp;#39;&amp;#39;&amp;#39;  

# CNN  
model = Sequential()  
model.add(  
Convolution2D(  
    32,  
    3,  
    3,  
    border_mode=&amp;#39;same&amp;#39;,  # 有做 zero-padding 的意思  
    input_shape=X_train[0].shape)  
)  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(Convolution2D(32, 3, 3))  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(MaxPooling2D(pool_size=(2, 2)))  
model.add(Dropout(0.2))  

model.add(Flatten())  

# DNN  
model.add(Dense(512))  
model.add(Activation(&amp;#39;relu&amp;#39;))  
model.add(Dropout(0.5))  
model.add(Dense(10))  
model.add(Activation(&amp;#39;softmax&amp;#39;))  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Tips for Setting Hyper-parameters  &lt;ul&gt;
&lt;li&gt;影像的大小須要能夠被 2 整除數次  &lt;/li&gt;
&lt;li&gt;Convolutional Layer  &lt;ul&gt;
&lt;li&gt;比起使用一個 size 較大的 filter (7x7),可以先嘗試連續使用數個 size 小的 filter (3x3)  &lt;/li&gt;
&lt;li&gt;Stride 的值與 filter size 相關,通常 stride ≤ (W_f - 1)/2  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Very deep CNN model (16+ Layers) 多使用 3x3 filter 與 stride 1  &lt;/li&gt;
&lt;li&gt;Zero-padding 與 pooling layer 是選擇性的結構  &lt;/li&gt;
&lt;li&gt;Zero-padding 的使用取決於是否要保留邊界的資訊  &lt;/li&gt;
&lt;li&gt;Pooling layer 旨在避免 overfitting 與降低 weights 的數量, 但也減少影像所包含資訊,一般不會大於 3x3  &lt;ul&gt;
&lt;li&gt;像圍棋就不太適合用 Pooling，因為可能會失真。所以 AlphaGo 其實只有用 Convolutional Layer，沒有用 Pooling Layer。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;嘗試修改有不錯效能的 model,會比建立一個全新的模型容易收斂,且 model weights 越多越難 tune 出好的參數  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Deep Learning Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://visualqa.org/"&gt;Visual Question Answering&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Video Captioning  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1701.00160.pdf"&gt;Text-To-Image&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1511.06434.pdf"&gt;Vector Arithmetic for Visual Concepts&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;Go Deeper in Deep Learning  &lt;ul&gt;
&lt;li&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/"&gt;Neural Networks and Deep Learning&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.iro.umontreal.ca/~bengioy/dlbook/"&gt;Deep Learning&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html"&gt;Course: Machine learning and having it deep and structured&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/"&gt;Keras documentation&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fchollet/keras"&gt;Keras GitHub&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ"&gt;台大電機李宏毅教授 Youtube 頻道&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.stanford.edu/"&gt;Convolutional Neural Networks for Visual Recognition cs231n&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果 feature 數量不夠的話，可以做些簡單的運算增加 feature 的量，尤其是已經知道這樣的 feature 會對 training 有幫助的話。  &lt;/li&gt;
&lt;li&gt;Keras model 相關的操作  &lt;ul&gt;
&lt;li&gt;用 &lt;code&gt;model.save()&lt;/code&gt; 來將訓練好的 model 存起來  &lt;/li&gt;
&lt;li&gt;之後可用 &lt;code&gt;keras.models.load_model()&lt;/code&gt; 來讀入已經訓練好的 model  &lt;/li&gt;
&lt;li&gt;讀入之後可再用 &lt;code&gt;model.summary()&lt;/code&gt; 來確認一下 model 的資訊  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.layers[0].get_weights()&lt;/code&gt; 可以得到此 model 第 1 層的 weights  &lt;/li&gt;
&lt;li&gt;用 &lt;code&gt;model.predict()&lt;/code&gt; 來預測結果  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當資料太大無法一次讀進來時，可以用 &lt;a href="https://keras.io/models/sequential/#fit_generator"&gt;Fit Generator&lt;/a&gt;。  &lt;ul&gt;
&lt;li&gt;需要自己撰寫一個 generator  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Deep Learning"></category><category term="Keras"></category><category term="CNN"></category><category term="DNN"></category></entry></feed>